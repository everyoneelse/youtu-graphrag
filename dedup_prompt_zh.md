# LLM去重Prompt中文翻译（最终版）

## 核心问题诊断

### ❌ 实际LLM输出（错误）

```json
{
  "representative": {
    "index": 0,
    "node_id": "entity_26",
    "description": "SE序列"
  },
  "duplicates": [
    {
      "index": 2,
      "node_id": "entity_45",
      "description": "自旋回波序列"
    }
  ],
  "rationale": ""SE序列"与"自旋回波序列"是同一 MRI 脉冲序列的简称与全称，
               二者指代完全相同的实体，可在任何语境下无损互换，故合并；
               选取更简洁且上下文已出现的"SE序列"作为代表。"
}
```

**问题分析：**
- LLM使用了**"更简洁"**（brevity）作为选择理由 ❌
- LLM使用了**"上下文已出现"**（frequency）作为选择理由 ❌
- 这些都是**不应该使用的选择标准**！

---

## 解决方案：明确禁止错误的选择理由

### 新增：禁止的代表选择标准

在原有的通用原则基础上，**明确列出禁止使用的理由**：

```
禁止的代表选择标准（不要使用这些理由来选择代表）：
✗ 简洁性："X更短" → 信息完整性优先于简洁性
✗ 上下文频率："X出现更频繁" → 描述性比频率更重要
✗ 字母顺序："X在字母顺序上靠前" → 任意排序无关紧要
✗ 索引顺序："X的索引更小" → 索引位置是任意的
✗ 熟悉度偏见："X对我来说更熟悉" → 使用客观原则

关键要求：信息完整性和自解释性优先于简洁性。
代表应该是信息量最大的表达，而不是最短的。
```

---

## 完整的改进版Prompt

### 1. 实体去重Prompt（中文版）

```
你是一个知识图谱管理助手，负责执行实体去重任务。
所有列出的三元组共享相同的头实体和关系。

头实体：{head}
关系：{relation}

头实体上下文：
{head_context}

候选尾实体：
{candidates}

任务：识别哪些尾实体是共指的（指代完全相同的实体/概念）。

基本原则：
共指要求指称同一性：两个表达必须指代完全相同的指称对象。
- 合并：'实体_A' 和 '实体_A_别名' → 相同指称对象（一个事物的不同名称）
- 不合并：'实体_X' 和 '实体_Y' → 不同指称对象（两个不同的事物）

关键区别 - 关系满足 vs 实体同一性：
⚠️  如果多个尾实体都满足与头实体H的关系R，这并不意味着它们是共指的。
每个尾实体可以是恰好满足同一关系的不同实体。
形式逻辑：(H,R,X) ∧ (H,R,Y) ↛ X=Y（关系满足不意味着实体同一性）

合并条件 - 必须全部满足：
1. 指称测试：两个尾实体是否指代现实世界中完全相同的实体？
   • 相同实体，不同名称 → 合并（例如：'NYC' = 'New York City'）
   • 不同实体 → 保持分离（即使高度相关）

2. 替换测试：你能在所有上下文中用一个尾实体替换另一个而不改变真值吗？
   • 如果替换改变含义/信息 → 保持分离
   • 如果替换保留含义 → 合并

3. 等价类：合并后，所有成员必须指代同一个单一实体。
   • 不要创建包含多个不同实体的组
   • 每个组 = 一个实体的不同语言表达

禁止的合并理由（这些不是合并的有效理由）：
✗ 共享关系："都满足与H的关系R" → 不足以构成共指
✗ 语义相似："X和Y相似/相关" → 相似性 ≠ 同一性
✗ 相同类别："都是类型T" → 类别成员资格 ≠ 实体同一性
✗ 共现："X和Y一起出现" → 上下文接近 ≠ 共指
✗ 功能关系："X导致/影响/包含Y" → 关系 ≠ 同一性
✗ 共享属性："X和Y有属性P" → 属性共享 ≠ 实体同一性
✗ 同一集合的一部分："X, Y ∈ 集合_S" → 集合成员资格 ≠ 元素同一性

多值关系：
许多关系将一个头实体映射到多个不同的尾实体。每个尾实体是一个独立的实例。
模式：如果H与关系R有{T1, T2, ..., Tn}，每个Ti通常是一个不同的实体。
只有当Ti和Tj是同一实体的不同名称时才合并它们，而不仅仅因为它们都满足R。

决策程序：
对于每对尾实体(Ti, Tj)：
  1. 问："Ti和Tj是否指代同一实体？"（不是"它们相关吗？"）
  2. 应用替换测试：交换它们会改变信息吗？
  3. 如果不确定 → 保持分离（保守原则）

保守原则：
错误分割（保持共指实体分离）< 错误合并（合并不同实体）
有疑问时，保留区别。

输出要求：
1. 每个输入索引必须恰好出现在一个组中
2. 每个组代表一个实体及其各种表达形式
3. 按照以下原则选择代表性表达（按优先级顺序）：
   a) 信息完整性：优先选择传达更多信息的表达
      • 完整形式 > 缩写（例如：'磁共振成像' > 'MRI'）
      • 完整名称 > 部分名称（例如：'北京市' > '北京'）
   b) 自解释性：优先选择无需领域知识即可理解的表达
      • 描述性术语 > 技术代码（例如：'高血压' > 'I10'）
      • 通用名称 > 化学式（例如：在通用语境下，'水' > 'H₂O'）
   c) 规范性：优先选择该领域的标准/官方形式
      • 官方名称 > 非正式名称
      • 现行名称 > 已废弃名称
   d) 无歧义性：优先选择歧义较少的表达
      • 特定术语 > 通用术语（例如：在医学语境下，'乙酰水杨酸' > '阿司匹林'）
   e) 当原则冲突时，根据知识图谱的目标受众确定优先级

禁止的代表选择标准（不要使用这些理由来选择代表）：
✗ 简洁性："X更短" → 信息完整性优先于简洁性
✗ 上下文频率："X出现更频繁" → 描述性比频率更重要
✗ 字母顺序："X在字母顺序上靠前" → 任意排序无关紧要
✗ 索引顺序："X的索引更小" → 索引位置是任意的
✗ 熟悉度偏见："X对我来说更熟悉" → 使用客观原则

关键要求：信息完整性和自解释性优先于简洁性。
代表应该是信息量最大的表达，而不是最短的。

4. 提供基于指称同一性和代表选择原则的清晰理由

使用以下严格的JSON格式响应：
{
  "groups": [
    {"members": [1, 3], "representative": 3, "rationale": "为什么这些表达是共指的（相同指称对象）。"}
  ]
}
```

---

### 2. 属性去重Prompt（中文版）

```
你是一个知识图谱管理助手，负责执行属性值去重任务。
所有列出的三元组共享相同的头实体和关系。

头实体：{head}
关系：{relation}

头实体上下文：
{head_context}

候选属性值：
{candidates}

任务：识别哪些属性值是等价的（表达完全相同的属性-值对）。

基本原则：
等价要求值同一性：两个表达必须指代完全相同的属性-值组合。
- 合并：'值_A' 和 '值_A_不同表达' → 相同值（不同表达）
- 不合并：'值_X' 和 '值_Y' → 不同值（不同的属性-值对）

关键区别 - 关系满足 vs 值同一性：
⚠️  如果多个值都满足与头实体H的关系R，这并不意味着它们是等价的。
每个值可以是恰好满足同一关系的不同属性/测量。
形式逻辑：(H,R,V1) ∧ (H,R,V2) ↛ V1=V2（共同满足不意味着值等价）

合并条件 - 必须全部满足：
1. 相同属性：两个值描述相同的属性/维度/特性。
   • 属性_A 和 属性_B → 保持分离（不同属性）
   • 属性_A 和 属性_A → 进入条件2

2. 相同值：两者表达该属性的相同测量/状态/数量。
   • 值_1 和 值_2 → 保持分离（不同值）
   • 值_X 和 值_X → 进入条件3

3. 语言变体：差异仅在表达上，而非含义上。
   可接受的变体：
   • 单位转换：'10厘米' = '100毫米'（相同长度，不同单位）
   • 语言：'水' = 'H₂O' = 'water'（相同物质，不同语言/记号）
   • 记法：'五十' = '50' = '5×10¹'（相同数字，不同表示）

禁止的合并理由（这些不是合并的有效理由）：
✗ 共享实体："都是H的属性" → 不足以构成等价
✗ 共享关系："都满足与H的关系R" → 不足以构成等价
✗ 相同领域："都来自领域D" → 领域成员资格 ≠ 值同一性
✗ 相关属性："属性_A影响属性_B" → 关系 ≠ 等价
✗ 相似量级："值_1 ≈ 值_2" → 相似性 ≠ 同一性
✗ 共现："V1和V2一起出现" → 相关性 ≠ 等价
✗ 模式的一部分："V1, V2 ∈ {属性集合}" → 集合成员资格 ≠ 元素同一性

多值属性：
许多实体对于同一关系类型拥有多个不同的属性值。
模式：如果H与关系R有{A1, A2, ..., An}，每个Ai通常是一个不同的属性值。
只有当Ai和Aj以不同方式表达相同的属性-值时才合并它们。

决策程序：
对于每对值(Vi, Vj)：
  1. 问："Vi和Vj表达相同的属性吗？" → 如果否，保持分离
  2. 问："Vi和Vj表达相同的值/测量吗？" → 如果否，保持分离
  3. 问："差异仅在语言/记号上吗？" → 如果否，保持分离
  4. 如果不确定 → 保持分离（保守原则）

保守原则：
错误分割（保持等价值分离）< 错误合并（合并不同值）
有疑问时，保留区别。

输出要求：
1. 每个输入索引必须恰好出现在一个组中
2. 每个组代表一个属性-值对及其各种表达形式
3. 按照以下原则选择代表性表达（按优先级顺序）：
   a) 信息完整性：优先选择传达更多信息的表达
      • 完整形式 > 缩写（例如：'磁共振成像' > 'MRI'）
      • 完整规格 > 部分规格（例如：'10 mg/天' > '10 mg'）
   b) 自解释性：优先选择无需领域知识即可理解的表达
      • 描述性术语 > 技术代码（例如：'高血压' > 'HTN'）
      • 通用名称 > 化学式（例如：在通用语境下，'水' > 'H₂O'）
   c) 规范性：优先选择该领域的标准/官方形式
      • 标准单位 > 非标准单位
      • 官方术语 > 口语术语
   d) 精确性：优先选择具有适当精度水平的表达
      • 精确值 > 近似值
      • 具体测量 > 一般描述
   e) 当原则冲突时，根据知识图谱的目标受众确定优先级

禁止的代表选择标准（不要使用这些理由来选择代表）：
✗ 简洁性："X更短" → 信息完整性优先于简洁性
✗ 上下文频率："X出现更频繁" → 描述性比频率更重要
✗ 字母顺序："X在字母顺序上靠前" → 任意排序无关紧要
✗ 索引顺序："X的索引更小" → 索引位置是任意的
✗ 熟悉度偏见："X对我来说更熟悉" → 使用客观原则

关键要求：信息完整性和自解释性优先于简洁性。
代表应该是信息量最大的表达，而不是最短的。

4. 提供基于值同一性和代表选择原则的清晰理由

使用以下严格的JSON格式响应：
{
  "groups": [
    {"members": [1, 3], "representative": 3, "rationale": "为什么这些是等价的（相同属性-值）。"}
  ]
}
```

---

## 改进历程总结

### 第1版（问题）
```
3. Choose the most informative expression as representative
```
❌ 太模糊，LLM理解不一致

### 第2版（不够好）
```
a) 优先选择完整形式而非缩写
b) 优先选择全称而非简称
c) 优先选择描述性术语而非首字母缩写
d) 优先选择信息量最大、最具自解释性的表达
e) 避免选择缩写/首字母缩写
```
❌ a、b、c、e都在说同一件事，只解决了缩写问题，无法处理同义词、化学式等其他情况

### 第3版（更好，但不够）
```
a) 信息完整性：完整形式 > 缩写
b) 自解释性：描述性术语 > 技术代码
c) 规范性：官方名称 > 非正式名称
d) 无歧义性：特定术语 > 通用术语
e) 受众适配：根据知识图谱的目标受众决定
```
✅ 定义了通用原则，可以处理多种情况
❌ 但LLM仍然可能使用"简洁性"等错误理由

### 第4版（最终版）✅
在第3版基础上新增：
```
禁止的代表选择标准（明确告诉LLM什么不能做）：
✗ 简洁性："X更短" → 信息完整性优先于简洁性
✗ 上下文频率："X出现更频繁" → 描述性比频率更重要
✗ 字母顺序："X在字母顺序上靠前" → 任意排序无关紧要
✗ 索引顺序："X的索引更小" → 索引位置是任意的
✗ 熟悉度偏见："X对我来说更熟悉" → 使用客观原则

关键要求：信息完整性和自解释性优先于简洁性。
代表应该是信息量最大的表达，而不是最短的。
```

---

## 预期效果对比

### 使用旧Prompt的错误输出
```json
{
  "representative": "SE序列",  // ❌ 错误
  "duplicates": ["自旋回波序列"],
  "rationale": "选取更简洁且上下文已出现的'SE序列'作为代表"  // ❌ 使用了禁止的理由
}
```

### 使用新Prompt的正确输出
```json
{
  "representative": "自旋回波序列",  // ✅ 正确
  "duplicates": ["SE序列"],
  "rationale": "'SE序列'与'自旋回波序列'指代同一MRI脉冲序列。根据信息完整性原则，选择完整形式'自旋回波序列'作为代表，因为它具有更好的自解释性，无需领域知识即可理解其含义。"  // ✅ 使用了正确的原则
}
```

---

## 关键改进点

1. **从模糊到明确**：从"most informative"到具体的5个原则
2. **从具体到通用**：从只处理缩写到可处理各种等价情况
3. **从正面指导到负面约束**：不仅告诉LLM应该做什么，还明确禁止错误的理由
4. **强调优先级**：明确"信息完整性 > 简洁性"

这样的prompt设计既有**通用性**（不依赖具体案例），又有**约束性**（防止LLM使用错误理由），应该能显著提高representative选择的质量。
