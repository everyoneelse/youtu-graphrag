# è¯­è¨€æ£€æµ‹é›†æˆæŒ‡å—

æœ¬æ–‡æ¡£æä¾›å°†è¯­è¨€æ£€æµ‹åŠŸèƒ½é›†æˆåˆ°Youtu-GraphRAGé¡¹ç›®çš„å®Œæ•´æ–¹æ¡ˆã€‚

---

## ğŸ“‹ é›†æˆæ¦‚è¿°

### é›†æˆç‚¹

1. **æ–‡æœ¬åˆ†å—** (`models/constructor/kt_gen.py`)
   - æ£€æµ‹æ–‡æœ¬è¯­è¨€
   - æ ¹æ®è¯­è¨€é€‰æ‹©åˆ†è¯ç­–ç•¥
   
2. **å®ä½“æå–** (`models/constructor/kt_gen.py`)
   - ä¸ºå®ä½“æ ‡è®°è¯­è¨€
   - æ”¯æŒå¤šè¯­è¨€å®ä½“å»é‡
   
3. **å…³ç³»æå–** (`models/constructor/kt_gen.py`)
   - æ£€æµ‹å…³ç³»æè¿°çš„è¯­è¨€
   - è·¨è¯­è¨€å…³ç³»é“¾æ¥
   
4. **æ£€ç´¢** (`models/retriever/enhanced_kt_retriever.py`)
   - æ£€æµ‹æŸ¥è¯¢è¯­è¨€
   - è¯­è¨€è¿‡æ»¤å’ŒåŒ¹é…
   
5. **ç¤¾åŒºæ‘˜è¦** (`models/constructor/kt_gen.py`)
   - æ£€æµ‹ç¤¾åŒºå†…å®¹çš„ä¸»è¦è¯­è¨€
   - æ”¯æŒå¤šè¯­è¨€æ‘˜è¦ç”Ÿæˆ

---

## ğŸ”§ é›†æˆæ­¥éª¤

### æ­¥éª¤1: å®‰è£…ä¾èµ–

```bash
# æ›´æ–° requirements.txt
echo "fasttext-wheel>=0.9.2" >> requirements.txt

# å®‰è£…
pip install -r requirements.txt

# ä¸‹è½½fastTextæ¨¡å‹
wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin -P models/
# æˆ–ä½¿ç”¨é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
wget https://hf-mirror.com/facebook/fasttext-language-identification/resolve/main/model.bin -O models/lid.176.bin
```

### æ­¥éª¤2: é…ç½®æ–‡ä»¶æ›´æ–°

åœ¨ `config/base_config.yaml` ä¸­æ·»åŠ é…ç½®ï¼š

```yaml
# è¯­è¨€æ£€æµ‹é…ç½®
language_detection:
  # æ˜¯å¦å¯ç”¨è¯­è¨€æ£€æµ‹
  enabled: true
  
  # æ£€æµ‹å™¨ç±»å‹: fasttext, lingua, langdetect, langid
  detector_type: fasttext
  
  # fastTextæ¨¡å‹è·¯å¾„
  model_path: models/lid.176.bin
  
  # æ˜¯å¦å¯ç”¨è‡ªåŠ¨fallback
  fallback: true
  
  # ç½®ä¿¡åº¦é˜ˆå€¼ (ä½äºæ­¤å€¼ä¼šå°è¯•fallback)
  confidence_threshold: 0.8
  
  # æ”¯æŒçš„è¯­è¨€åˆ—è¡¨ (ç”¨äºè¿‡æ»¤å’ŒéªŒè¯)
  supported_languages:
    - en  # è‹±è¯­
    - zh  # ä¸­æ–‡
    - ja  # æ—¥è¯­
    - ko  # éŸ©è¯­
    - fr  # æ³•è¯­
    - de  # å¾·è¯­
    - es  # è¥¿ç­ç‰™è¯­
    - ru  # ä¿„è¯­
    - ar  # é˜¿æ‹‰ä¼¯è¯­
    - pt  # è‘¡è„ç‰™è¯­
  
  # æ˜¯å¦åœ¨å®ä½“/å…³ç³»ä¸­ä¿å­˜è¯­è¨€ä¿¡æ¯
  save_language_info: true
  
  # æ˜¯å¦æ ¹æ®è¯­è¨€åˆ†åˆ«ç´¢å¼•
  language_aware_indexing: true
```

### æ­¥éª¤3: æ›´æ–°é…ç½®åŠ è½½å™¨

æ›´æ–° `config/config_loader.py`ï¼š

```python
def get_language_detection_config():
    """è·å–è¯­è¨€æ£€æµ‹é…ç½®"""
    config = load_config()
    return config.get('language_detection', {
        'enabled': True,
        'detector_type': 'fasttext',
        'model_path': 'models/lid.176.bin',
        'fallback': True,
        'confidence_threshold': 0.8,
        'supported_languages': ['en', 'zh', 'ja', 'ko'],
        'save_language_info': True,
        'language_aware_indexing': False
    })
```

### æ­¥éª¤4: é›†æˆåˆ°KTBuilder

ä¿®æ”¹ `models/constructor/kt_gen.py`ï¼š

```python
from utils.language_detector import LanguageDetector, DetectorType, get_global_detector
from config.config_loader import get_language_detection_config

class KTBuilder:
    def __init__(self, ...):
        # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...
        
        # åˆå§‹åŒ–è¯­è¨€æ£€æµ‹å™¨
        self.lang_config = get_language_detection_config()
        if self.lang_config.get('enabled', False):
            self.lang_detector = self._init_language_detector()
            logger.info("âœ“ è¯­è¨€æ£€æµ‹å™¨å·²å¯ç”¨")
        else:
            self.lang_detector = None
            logger.info("è¯­è¨€æ£€æµ‹å™¨æœªå¯ç”¨")
    
    def _init_language_detector(self):
        """åˆå§‹åŒ–è¯­è¨€æ£€æµ‹å™¨"""
        try:
            detector_type_str = self.lang_config.get('detector_type', 'fasttext')
            detector_type = DetectorType(detector_type_str)
            
            detector = LanguageDetector(
                detector_type=detector_type,
                fallback=self.lang_config.get('fallback', True),
                fasttext_model_path=self.lang_config.get('model_path')
            )
            return detector
        except Exception as e:
            logger.warning(f"è¯­è¨€æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}, å°†ç¦ç”¨è¯­è¨€æ£€æµ‹åŠŸèƒ½")
            return None
    
    def _detect_language(self, text: str) -> tuple:
        """æ£€æµ‹æ–‡æœ¬è¯­è¨€"""
        if not self.lang_detector:
            return ('unknown', 0.0)
        
        try:
            lang, conf = self.lang_detector.detect(text)
            
            # éªŒè¯æ˜¯å¦åœ¨æ”¯æŒçš„è¯­è¨€åˆ—è¡¨ä¸­
            supported = self.lang_config.get('supported_languages', [])
            if supported and lang not in supported:
                logger.debug(f"æ£€æµ‹åˆ°ä¸æ”¯æŒçš„è¯­è¨€: {lang}, å°†æ ‡è®°ä¸ºunknown")
                return ('unknown', conf)
            
            return (lang, conf)
        except Exception as e:
            logger.error(f"è¯­è¨€æ£€æµ‹å¤±è´¥: {e}")
            return ('unknown', 0.0)
    
    # åœ¨æ–‡æœ¬åˆ†å—æ—¶æ£€æµ‹è¯­è¨€
    def chunk_text(self, text: str):
        """æ–‡æœ¬åˆ†å— - é›†æˆè¯­è¨€æ£€æµ‹"""
        
        # æ£€æµ‹æ–‡æœ¬è¯­è¨€
        doc_lang, lang_conf = self._detect_language(text)
        logger.info(f"æ–‡æ¡£è¯­è¨€: {doc_lang} (ç½®ä¿¡åº¦: {lang_conf:.2f})")
        
        # æ ¹æ®è¯­è¨€é€‰æ‹©åˆ†è¯ç­–ç•¥
        if doc_lang in ['zh', 'ja']:
            # ä¸­æ—¥æ–‡ä½¿ç”¨å­—ç¬¦çº§æˆ–ä¸“ç”¨åˆ†è¯
            chunks = self._chunk_cjk(text, lang=doc_lang)
        elif doc_lang in ['ko']:
            # éŸ©æ–‡å¤„ç†
            chunks = self._chunk_korean(text)
        else:
            # å…¶ä»–è¯­è¨€ä½¿ç”¨ç©ºæ ¼åˆ†è¯
            chunks = self._chunk_latin(text, lang=doc_lang)
        
        # ä¸ºæ¯ä¸ªchunkæ·»åŠ è¯­è¨€ä¿¡æ¯
        for chunk in chunks:
            chunk['language'] = doc_lang
            chunk['language_confidence'] = lang_conf
        
        return chunks
    
    # åœ¨å®ä½“æå–æ—¶æ ‡è®°è¯­è¨€
    def extract_entities(self, text: str):
        """å®ä½“æå– - é›†æˆè¯­è¨€æ£€æµ‹"""
        
        # æ£€æµ‹æ–‡æœ¬è¯­è¨€
        text_lang, _ = self._detect_language(text)
        
        # è°ƒç”¨LLMæå–å®ä½“
        entities = self._extract_entities_llm(text)
        
        # ä¸ºæ¯ä¸ªå®ä½“æ ‡è®°è¯­è¨€
        if self.lang_config.get('save_language_info', True):
            for entity in entities:
                # æ£€æµ‹å®ä½“æœ¬èº«çš„è¯­è¨€
                entity_lang, entity_conf = self._detect_language(entity['name'])
                entity['language'] = entity_lang
                entity['language_confidence'] = entity_conf
                entity['context_language'] = text_lang
        
        return entities
    
    # åœ¨å…³ç³»æå–æ—¶æ ‡è®°è¯­è¨€
    def extract_relations(self, text: str):
        """å…³ç³»æå– - é›†æˆè¯­è¨€æ£€æµ‹"""
        
        text_lang, _ = self._detect_language(text)
        
        relations = self._extract_relations_llm(text)
        
        if self.lang_config.get('save_language_info', True):
            for relation in relations:
                # æ£€æµ‹å…³ç³»æè¿°çš„è¯­è¨€
                rel_lang, rel_conf = self._detect_language(relation.get('description', ''))
                relation['language'] = rel_lang
                relation['context_language'] = text_lang
        
        return relations
    
    # ç¤¾åŒºæ‘˜è¦ç”Ÿæˆæ—¶è€ƒè™‘è¯­è¨€
    def generate_community_summary(self, community_nodes, community_edges):
        """ç¤¾åŒºæ‘˜è¦ - è€ƒè™‘è¯­è¨€"""
        
        # ç»Ÿè®¡ç¤¾åŒºä¸­çš„è¯­è¨€åˆ†å¸ƒ
        lang_counter = {}
        for node in community_nodes:
            lang = node.get('language', 'unknown')
            lang_counter[lang] = lang_counter.get(lang, 0) + 1
        
        # ç¡®å®šä¸»è¦è¯­è¨€
        main_lang = max(lang_counter.items(), key=lambda x: x[1])[0] if lang_counter else 'en'
        logger.info(f"ç¤¾åŒºä¸»è¦è¯­è¨€: {main_lang}")
        
        # æ ¹æ®ä¸»è¦è¯­è¨€ç”Ÿæˆæ‘˜è¦
        if main_lang == 'zh':
            summary = self._generate_summary_chinese(community_nodes, community_edges)
        elif main_lang == 'ja':
            summary = self._generate_summary_japanese(community_nodes, community_edges)
        else:
            summary = self._generate_summary_english(community_nodes, community_edges)
        
        return {
            'summary': summary,
            'language': main_lang,
            'language_distribution': lang_counter
        }
```

### æ­¥éª¤5: é›†æˆåˆ°æ£€ç´¢å™¨

ä¿®æ”¹ `models/retriever/enhanced_kt_retriever.py`ï¼š

```python
from utils.language_detector import get_global_detector
from config.config_loader import get_language_detection_config

class KTRetriever:
    def __init__(self, ...):
        # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...
        
        # åˆå§‹åŒ–è¯­è¨€æ£€æµ‹å™¨
        self.lang_config = get_language_detection_config()
        if self.lang_config.get('enabled', False):
            self.lang_detector = get_global_detector()
        else:
            self.lang_detector = None
    
    def retrieve(self, query: str, top_k: int = 10):
        """æ£€ç´¢ - è€ƒè™‘æŸ¥è¯¢è¯­è¨€"""
        
        # æ£€æµ‹æŸ¥è¯¢è¯­è¨€
        query_lang = 'unknown'
        if self.lang_detector:
            query_lang, query_conf = self.lang_detector.detect(query)
            logger.info(f"æŸ¥è¯¢è¯­è¨€: {query_lang} (ç½®ä¿¡åº¦: {query_conf:.2f})")
        
        # æ‰§è¡Œæ£€ç´¢
        results = self._retrieve_core(query, top_k)
        
        # å¦‚æœå¯ç”¨è¯­è¨€æ„ŸçŸ¥ç´¢å¼•ï¼Œè¿›è¡Œè¯­è¨€è¿‡æ»¤
        if self.lang_config.get('language_aware_indexing', False):
            results = self._filter_by_language(results, query_lang)
        
        return results
    
    def _filter_by_language(self, results, query_lang):
        """æ ¹æ®è¯­è¨€è¿‡æ»¤ç»“æœ"""
        if query_lang == 'unknown':
            return results
        
        # ä¼˜å…ˆè¿”å›åŒè¯­è¨€çš„ç»“æœ
        same_lang_results = [r for r in results if r.get('language') == query_lang]
        other_results = [r for r in results if r.get('language') != query_lang]
        
        # åŒè¯­è¨€ç»“æœæ’åœ¨å‰é¢
        return same_lang_results + other_results
```

---

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: æ„å»ºå¤šè¯­è¨€çŸ¥è¯†å›¾è°±

```python
from models.constructor.kt_gen import KTBuilder

# åˆå§‹åŒ–æ„å»ºå™¨
builder = KTBuilder(
    llm_config=llm_config,
    schema_path="schemas/your_schema.yaml"
)

# æ„å»ºå¤šè¯­è¨€æ–‡æ¡£
documents = [
    {"text": "Einstein developed the theory of relativity...", "id": "doc1"},
    {"text": "çˆ±å› æ–¯å¦æå‡ºäº†ç›¸å¯¹è®º...", "id": "doc2"},
    {"text": "ã‚¢ã‚¤ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã¯ç›¸å¯¾æ€§ç†è«–ã‚’ç™ºå±•ã•ã›ãŸ...", "id": "doc3"},
]

# è‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶æ„å»ºå›¾è°±
graph = builder.build_graph(documents)

# æŸ¥çœ‹è¯­è¨€åˆ†å¸ƒ
print("è¯­è¨€åˆ†å¸ƒ:", graph.language_stats)
```

### ç¤ºä¾‹2: å¤šè¯­è¨€æ£€ç´¢

```python
from models.retriever.enhanced_kt_retriever import KTRetriever

retriever = KTRetriever(graph_path="output/graphs/my_graph.json")

# ä¸­æ–‡æŸ¥è¯¢
results_zh = retriever.retrieve("ç›¸å¯¹è®ºæ˜¯ä»€ä¹ˆ?")

# è‹±æ–‡æŸ¥è¯¢
results_en = retriever.retrieve("What is relativity?")

# æŸ¥çœ‹ç»“æœè¯­è¨€
for r in results_zh:
    print(f"ç»“æœ: {r['text'][:50]}, è¯­è¨€: {r.get('language', 'unknown')}")
```

---

## ğŸ¯ é«˜çº§åŠŸèƒ½

### åŠŸèƒ½1: è·¨è¯­è¨€å®ä½“é“¾æ¥

```python
def link_cross_language_entities(self, entities):
    """é“¾æ¥è·¨è¯­è¨€çš„ç›¸åŒå®ä½“"""
    
    # æŒ‰è¯­è¨€åˆ†ç»„
    entities_by_lang = {}
    for entity in entities:
        lang = entity.get('language', 'unknown')
        if lang not in entities_by_lang:
            entities_by_lang[lang] = []
        entities_by_lang[lang].append(entity)
    
    # ä½¿ç”¨embeddingè¿›è¡Œè·¨è¯­è¨€åŒ¹é…
    cross_lang_links = []
    for lang1, entities1 in entities_by_lang.items():
        for lang2, entities2 in entities_by_lang.items():
            if lang1 >= lang2:
                continue
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            links = self._find_similar_entities(entities1, entities2)
            cross_lang_links.extend(links)
    
    return cross_lang_links
```

### åŠŸèƒ½2: è¯­è¨€æ„ŸçŸ¥çš„æŸ¥è¯¢æ‰©å±•

```python
def expand_query_multilingual(self, query: str):
    """å¤šè¯­è¨€æŸ¥è¯¢æ‰©å±•"""
    
    query_lang, _ = self.lang_detector.detect(query)
    
    expanded_queries = [query]
    
    # å¦‚æœæ˜¯è‹±æ–‡æŸ¥è¯¢ï¼Œè€ƒè™‘æ·»åŠ ä¸­æ–‡ç¿»è¯‘
    if query_lang == 'en':
        # è°ƒç”¨ç¿»è¯‘APIæˆ–ä½¿ç”¨é¢„å®šä¹‰è¯å…¸
        zh_query = self.translate(query, target_lang='zh')
        expanded_queries.append(zh_query)
    
    # å¦‚æœæ˜¯ä¸­æ–‡æŸ¥è¯¢ï¼Œè€ƒè™‘æ·»åŠ è‹±æ–‡ç¿»è¯‘
    elif query_lang == 'zh':
        en_query = self.translate(query, target_lang='en')
        expanded_queries.append(en_query)
    
    return expanded_queries
```

### åŠŸèƒ½3: è¯­è¨€ç»Ÿè®¡å’Œåˆ†æ

```python
def analyze_graph_languages(self, graph):
    """åˆ†æå›¾è°±çš„è¯­è¨€ç»Ÿè®¡ä¿¡æ¯"""
    
    stats = {
        'entities': {},
        'relations': {},
        'communities': {},
        'overall': {}
    }
    
    # ç»Ÿè®¡å®ä½“è¯­è¨€
    for entity in graph.entities:
        lang = entity.get('language', 'unknown')
        stats['entities'][lang] = stats['entities'].get(lang, 0) + 1
    
    # ç»Ÿè®¡å…³ç³»è¯­è¨€
    for relation in graph.relations:
        lang = relation.get('language', 'unknown')
        stats['relations'][lang] = stats['relations'].get(lang, 0) + 1
    
    # ç»Ÿè®¡ç¤¾åŒºä¸»è¦è¯­è¨€
    for community in graph.communities:
        lang = community.get('language', 'unknown')
        stats['communities'][lang] = stats['communities'].get(lang, 0) + 1
    
    # æ•´ä½“ç»Ÿè®¡
    all_langs = list(stats['entities'].keys()) + list(stats['relations'].keys())
    from collections import Counter
    stats['overall'] = dict(Counter(all_langs))
    
    return stats
```

---

## ğŸ” è°ƒè¯•å’Œç›‘æ§

### 1. æ—¥å¿—è®°å½•

```python
import logging

logger = logging.getLogger(__name__)

# åœ¨å…³é”®ä½ç½®æ·»åŠ æ—¥å¿—
def process_text(self, text):
    lang, conf = self._detect_language(text)
    logger.info(f"å¤„ç†æ–‡æœ¬ - è¯­è¨€: {lang}, ç½®ä¿¡åº¦: {conf:.2f}, é•¿åº¦: {len(text)}")
    
    if conf < 0.5:
        logger.warning(f"ä½ç½®ä¿¡åº¦è¯­è¨€æ£€æµ‹: {lang} ({conf:.2f})")
```

### 2. æ€§èƒ½ç›‘æ§

```python
import time

def monitor_language_detection(func):
    """è£…é¥°å™¨: ç›‘æ§è¯­è¨€æ£€æµ‹æ€§èƒ½"""
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        elapsed = time.time() - start
        
        if elapsed > 0.1:  # è¶…è¿‡100ms
            logger.warning(f"è¯­è¨€æ£€æµ‹è€—æ—¶è¿‡é•¿: {elapsed*1000:.2f}ms")
        
        return result
    return wrapper
```

### 3. å‡†ç¡®ç‡ç›‘æ§

```python
def validate_language_detection(self, sample_size=100):
    """éªŒè¯è¯­è¨€æ£€æµ‹å‡†ç¡®ç‡"""
    
    # ä»å›¾è°±ä¸­éšæœºæŠ½æ ·
    samples = random.sample(self.graph.entities, sample_size)
    
    correct = 0
    for entity in samples:
        # é‡æ–°æ£€æµ‹è¯­è¨€
        detected_lang, _ = self._detect_language(entity['name'])
        stored_lang = entity.get('language', 'unknown')
        
        if detected_lang == stored_lang:
            correct += 1
    
    accuracy = correct / sample_size
    logger.info(f"è¯­è¨€æ£€æµ‹å‡†ç¡®ç‡: {accuracy*100:.2f}%")
    
    return accuracy
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–

```python
# âœ… å¥½: ä½¿ç”¨å…¨å±€å•ä¾‹
detector = get_global_detector()

# âŒ å·®: æ¯æ¬¡éƒ½åˆ›å»ºæ–°å®ä¾‹
detector = LanguageDetector()  # ä¼šé‡æ–°åŠ è½½æ¨¡å‹
```

### 2. æ‰¹é‡å¤„ç†

```python
# âœ… å¥½: æ‰¹é‡æ£€æµ‹
texts = [entity['name'] for entity in entities]
results = detector.detect_batch(texts)

# âŒ å·®: é€ä¸ªæ£€æµ‹
for entity in entities:
    lang, conf = detector.detect(entity['name'])
```

### 3. é”™è¯¯å¤„ç†

```python
# âœ… å¥½: æœ‰å®¹é”™æœºåˆ¶
try:
    lang, conf = detector.detect(text)
    if conf < threshold:
        lang = 'unknown'
except Exception as e:
    logger.error(f"è¯­è¨€æ£€æµ‹å¤±è´¥: {e}")
    lang, conf = 'unknown', 0.0

# âŒ å·®: æ²¡æœ‰é”™è¯¯å¤„ç†
lang, conf = detector.detect(text)  # å¯èƒ½æŠ›å‡ºå¼‚å¸¸
```

### 4. ç¼“å­˜ç»“æœ

```python
# âœ… å¥½: ç¼“å­˜é‡å¤æ£€æµ‹
from functools import lru_cache

@lru_cache(maxsize=1000)
def detect_language_cached(text):
    return detector.detect(text)
```

---

## ğŸ§ª æµ‹è¯•

### å•å…ƒæµ‹è¯•

åˆ›å»º `tests/test_language_detection_integration.py`:

```python
import unittest
from models.constructor.kt_gen import KTBuilder

class TestLanguageDetectionIntegration(unittest.TestCase):
    
    def setUp(self):
        self.builder = KTBuilder(...)
    
    def test_detect_chinese(self):
        text = "è¿™æ˜¯ä¸­æ–‡æ–‡æœ¬"
        lang, conf = self.builder._detect_language(text)
        self.assertEqual(lang, 'zh')
        self.assertGreater(conf, 0.8)
    
    def test_detect_english(self):
        text = "This is English text"
        lang, conf = self.builder._detect_language(text)
        self.assertEqual(lang, 'en')
        self.assertGreater(conf, 0.8)
    
    def test_entity_language_tagging(self):
        text = "Einstein was a physicist"
        entities = self.builder.extract_entities(text)
        for entity in entities:
            self.assertIn('language', entity)
            self.assertIn('language_confidence', entity)

if __name__ == '__main__':
    unittest.main()
```

---

## ğŸ“¦ éƒ¨ç½²æ¸…å•

- [ ] å®‰è£…fasttext-wheelä¾èµ–
- [ ] ä¸‹è½½lid.176.binæ¨¡å‹æ–‡ä»¶
- [ ] æ›´æ–°config/base_config.yamlé…ç½®
- [ ] é›†æˆlanguage_detectoråˆ°KTBuilder
- [ ] é›†æˆlanguage_detectoråˆ°KTRetriever
- [ ] æ·»åŠ è¯­è¨€æ£€æµ‹æ—¥å¿—
- [ ] è¿è¡ŒåŸºå‡†æµ‹è¯•éªŒè¯å‡†ç¡®ç‡
- [ ] è¿è¡Œé›†æˆæµ‹è¯•
- [ ] æ›´æ–°æ–‡æ¡£
- [ ] éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

---

## ğŸ‰ é¢„æœŸæ”¶ç›Š

1. **å¤šè¯­è¨€æ”¯æŒ**: è‡ªåŠ¨è¯†åˆ«å’Œå¤„ç†176ç§è¯­è¨€
2. **æ›´å¥½çš„åˆ†è¯**: æ ¹æ®è¯­è¨€é€‰æ‹©æœ€ä½³åˆ†è¯ç­–ç•¥
3. **è¯­è¨€æ„ŸçŸ¥æ£€ç´¢**: æé«˜è·¨è¯­è¨€æŸ¥è¯¢çš„å‡†ç¡®æ€§
4. **å®ä½“é“¾æ¥**: æ”¯æŒè·¨è¯­è¨€å®ä½“å¯¹é½
5. **ç»Ÿè®¡åˆ†æ**: äº†è§£çŸ¥è¯†å›¾è°±çš„è¯­è¨€åˆ†å¸ƒ

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
- [è¯­è¨€æ£€æµ‹å¯¹æ¯”æ–‡æ¡£](LANGUAGE_DETECTION_COMPARISON.md)
- [å¿«é€Ÿå¼€å§‹æŒ‡å—](LANGUAGE_DETECTION_QUICKSTART.md)
- [ç¤ºä¾‹ä»£ç ](example_language_detection.py)
