# HeadèŠ‚ç‚¹å»é‡ - å¿«é€Ÿå¼€å§‹

**5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹æŒ‡å—**

---

## ğŸ“– èƒŒæ™¯

æ‚¨å·²ç»å®ç°äº†**tailå»é‡**ï¼ˆå¯¹å…±äº«headå’Œrelationçš„tailåˆ—è¡¨å»é‡ï¼‰ï¼Œç°åœ¨éœ€è¦å®ç°**headå»é‡**ï¼ˆå¯¹æŒ‡ä»£åŒä¸€å®ä½“çš„ä¸åŒheadèŠ‚ç‚¹å»é‡ï¼‰ã€‚

### é—®é¢˜ç¤ºä¾‹

```
å½“å‰çŠ¶æ€ï¼ˆæœ‰é‡å¤ï¼‰:
  entity_0 (name: "åŒ—äº¬")    â†’ capital_of â†’ entity_10 (name: "ä¸­å›½")
  entity_5 (name: "åŒ—äº¬å¸‚")  â†’ located_in â†’ entity_15 (name: "ååŒ—")
  entity_8 (name: "Beijing") â†’ has_population â†’ entity_20 (name: "2100ä¸‡")

æœŸæœ›çŠ¶æ€ï¼ˆå»é‡åï¼‰:
  entity_0 (name: "åŒ—äº¬")    â†’ capital_of â†’ entity_10
                            â†’ located_in â†’ entity_15  
                            â†’ has_population â†’ entity_20
  
  [entity_5 å’Œ entity_8 è¢«åˆå¹¶åˆ° entity_0ï¼Œæ‰€æœ‰å…³ç³»è½¬ç§»]
```

---

## ğŸ¯ æ ¸å¿ƒæ–¹æ¡ˆ

### æ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phase 1: ç²¾ç¡®åŒ¹é…å»é‡          â”‚
â”‚   "åŒ—äº¬" = "åŒ—äº¬" âœ“              â”‚
â”‚   O(n) å¤æ‚åº¦ï¼Œå¿«é€Ÿ              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phase 2: è¯­ä¹‰ç›¸ä¼¼åº¦å»é‡        â”‚
â”‚   "åŒ—äº¬" â‰ˆ "åŒ—äº¬å¸‚" âœ“            â”‚
â”‚   "åŒ—äº¬" â‰ˆ "Beijing" âœ“           â”‚
â”‚   ä½¿ç”¨Embedding + LLMï¼ˆå¯é€‰ï¼‰    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phase 3: å›¾ç»“æ„æ›´æ–°            â”‚
â”‚   â€¢ è½¬ç§»æ‰€æœ‰è¾¹ï¼ˆå…¥è¾¹+å‡ºè¾¹ï¼‰       â”‚
â”‚   â€¢ åˆå¹¶èŠ‚ç‚¹å±æ€§                 â”‚
â”‚   â€¢ è®°å½•æº¯æºä¿¡æ¯                 â”‚
â”‚   â€¢ åˆ é™¤é‡å¤èŠ‚ç‚¹                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®ç‰¹ç‚¹

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| âœ… **ä¸¤é˜¶æ®µå¤„ç†** | ç²¾ç¡®åŒ¹é… + è¯­ä¹‰å»é‡ï¼Œä¸tailå»é‡ä¿æŒä¸€è‡´ |
| âœ… **ä¿å®ˆç­–ç•¥** | ä¸ç¡®å®šæ—¶ä¿æŒåˆ†ç¦»ï¼Œé¿å…é”™è¯¯åˆå¹¶ |
| âœ… **å®Œæ•´æº¯æº** | è®°å½•æ‰€æœ‰åˆå¹¶å†å²å’Œä¾æ® |
| âœ… **å›¾ç»“æ„å®‰å…¨** | äº‹åŠ¡æ€§æ“ä½œï¼Œä¿è¯å®Œæ•´æ€§ |
| âœ… **å¯æ‰©å±•** | æ”¯æŒå¤§è§„æ¨¡å›¾è°±çš„æ‰¹å¤„ç† |

---

## ğŸš€ å¿«é€Ÿé›†æˆï¼ˆ3æ­¥ï¼‰

### Step 1: æ·»åŠ ä»£ç åˆ°é¡¹ç›®

å°†ä»¥ä¸‹æ–‡ä»¶å†…å®¹åˆå¹¶åˆ° `models/constructor/kt_gen.py`:

```python
# ä» head_deduplication_reference.py å¤åˆ¶æ‰€æœ‰æ–¹æ³•åˆ° KnowledgeTreeGen ç±»
# æˆ–è€…ä½¿ç”¨Mixinç»§æ‰¿ï¼ˆæ¨èï¼‰

from head_deduplication_reference import HeadDeduplicationMixin

class KnowledgeTreeGen(HeadDeduplicationMixin, ...):
    # ç°åœ¨è‡ªåŠ¨å…·æœ‰ä»¥ä¸‹æ–¹æ³•ï¼š
    # - deduplicate_heads()
    # - validate_graph_integrity_after_head_dedup()
    # - export_head_merge_candidates_for_review()
    pass
```

### Step 2: æ·»åŠ é…ç½®

åœ¨ `config/base_config.yaml` ä¸­æ·»åŠ :

```yaml
semantic_dedup:
  # ... ç°æœ‰é…ç½® ...
  
  head_dedup:
    enabled: true
    enable_semantic: true
    similarity_threshold: 0.85
    use_llm_validation: false
    max_candidates: 1000
```

### Step 3: åœ¨Pipelineä¸­è°ƒç”¨

```python
# åœ¨å¤„ç†å®Œæ–‡æ¡£å’Œtailå»é‡åï¼Œæ·»åŠ headå»é‡
def build_graph(documents):
    builder = KnowledgeTreeGen(dataset_name="demo")
    
    # 1. å¤„ç†æ–‡æ¡£
    for doc in documents:
        builder.process_document(doc)
    
    # 2. Tailå»é‡ï¼ˆç°æœ‰ï¼‰
    builder.triple_deduplicate_semantic()
    
    # 3. ã€æ–°å¢ã€‘Headå»é‡
    stats = builder.deduplicate_heads(
        enable_semantic=True,
        similarity_threshold=0.85,
        use_llm_validation=False,
        max_candidates=1000
    )
    
    print(f"âœ“ Merged {stats['total_merges']} head nodes")
    
    return builder
```

---

## ğŸ“Š å‚æ•°é…ç½®æŒ‡å—

### å¿«é€Ÿé€‰æ‹©é…ç½®æ¨¡å¼

| åœºæ™¯ | é…ç½® |
|------|------|
| **å¿«é€Ÿæ¨¡å¼**ï¼ˆæ€§èƒ½ä¼˜å…ˆï¼‰ | `enable_semantic=False` |
| **å¹³è¡¡æ¨¡å¼**ï¼ˆæ¨èï¼‰ | `enable_semantic=True, threshold=0.85, use_llm=False` |
| **é«˜ç²¾åº¦æ¨¡å¼**ï¼ˆè´¨é‡ä¼˜å…ˆï¼‰ | `enable_semantic=True, threshold=0.90, use_llm=True` |

### å‚æ•°è¯¦è§£

#### `similarity_threshold` - æœ€é‡è¦å‚æ•°

```
0.95-1.00: æä¸¥æ ¼ï¼Œå‡ ä¹åªåˆå¹¶å®Œå…¨ç›¸åŒçš„
0.90-0.95: ä¸¥æ ¼ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ
0.85-0.90: å¹³è¡¡ï¼Œæ¨èé»˜è®¤  â† æ¨è
0.70-0.85: å®½æ¾ï¼Œé€‚åˆæ¢ç´¢åˆ†æ
0.00-0.70: å¤ªå®½æ¾ï¼Œä¸æ¨è
```

#### `use_llm_validation`

- `false`: å¿«é€Ÿæ¨¡å¼ï¼Œä»…ç”¨embeddingåˆ¤æ–­ï¼ˆæ¨èï¼‰
- `true`: é«˜ç²¾åº¦æ¨¡å¼ï¼ŒLLMäºŒæ¬¡éªŒè¯ï¼ˆæ…¢ä½†å‡†ï¼‰

#### `max_candidates`

æ ¹æ®å›¾è§„æ¨¡è°ƒæ•´ï¼š
- å°å›¾è°± (< 1kå®ä½“): `1000-5000`
- ä¸­å›¾è°± (1k-10k): `500-1000`  â† æ¨è
- å¤§å›¾è°± (> 10k): `200-500`

---

## ğŸ“ æ–‡æ¡£ç»“æ„

æœ¬æ¬¡æä¾›çš„å®Œæ•´æ–¹æ¡ˆåŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š

```
/workspace/
â”œâ”€â”€ HEAD_DEDUPLICATION_SOLUTION.md           # å®Œæ•´æ–¹æ¡ˆè®¾è®¡ï¼ˆå¿…è¯»ï¼‰
â”œâ”€â”€ head_deduplication_reference.py          # å‚è€ƒå®ç°ä»£ç 
â”œâ”€â”€ example_head_deduplication.py            # 8ä¸ªä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ HEAD_DEDUP_IMPLEMENTATION_GUIDE.md       # è¯¦ç»†é›†æˆæŒ‡å—
â””â”€â”€ HEAD_DEDUP_QUICKSTART.md                 # æœ¬æ–‡æ¡£ï¼ˆå¿«é€Ÿå¼€å§‹ï¼‰
```

### é˜…è¯»é¡ºåº

1. **å¿«é€Ÿäº†è§£** â†’ æœ¬æ–‡æ¡£ï¼ˆ5åˆ†é’Ÿï¼‰
2. **æ·±å…¥ç†è§£** â†’ `HEAD_DEDUPLICATION_SOLUTION.md`ï¼ˆ30åˆ†é’Ÿï¼‰
3. **å¼€å§‹ç¼–ç ** â†’ `HEAD_DEDUP_IMPLEMENTATION_GUIDE.md` + å‚è€ƒå®ç°
4. **å­¦ä¹ ç”¨æ³•** â†’ `example_head_deduplication.py`

---

## ğŸ§ª å¿«é€Ÿæµ‹è¯•

### æœ€å°å¯è¿è¡Œç¤ºä¾‹

```python
from models.constructor.kt_gen import KnowledgeTreeGen

# åˆ›å»ºæ„å»ºå™¨
builder = KnowledgeTreeGen(dataset_name="test")

# æ‰‹åŠ¨æ·»åŠ æµ‹è¯•æ•°æ®
builder.graph.add_node("entity_0", label="entity", properties={"name": "åŒ—äº¬"})
builder.graph.add_node("entity_1", label="entity", properties={"name": "åŒ—äº¬å¸‚"})
builder.graph.add_node("entity_2", label="entity", properties={"name": "ä¸Šæµ·"})

# æ·»åŠ ä¸€äº›è¾¹
builder.graph.add_edge("entity_0", "entity_2", relation="nearby")
builder.graph.add_edge("entity_1", "entity_2", relation="located_with")

print(f"Before dedup: {builder.graph.number_of_nodes()} nodes")

# æ‰§è¡Œå»é‡
stats = builder.deduplicate_heads(
    enable_semantic=True,
    similarity_threshold=0.85,
    use_llm_validation=False
)

print(f"After dedup: {stats['final_entity_count']} nodes")
print(f"Merged: {stats['total_merges']} nodes")

# éªŒè¯å®Œæ•´æ€§
issues = builder.validate_graph_integrity_after_head_dedup()
print(f"Integrity: {'âœ“ OK' if not any(issues.values()) else 'âš  Issues found'}")
```

---

## âš¡ æ€§èƒ½é¢„æœŸ

| å›¾è§„æ¨¡ | é…ç½® | é¢„æœŸæ—¶é—´ |
|--------|------|----------|
| 100å®ä½“ | å¹³è¡¡æ¨¡å¼ | < 5ç§’ |
| 1,000å®ä½“ | å¹³è¡¡æ¨¡å¼ | 10-30ç§’ |
| 10,000å®ä½“ | å¹³è¡¡æ¨¡å¼ | 1-5åˆ†é’Ÿ |
| 100,000å®ä½“ | å¹³è¡¡æ¨¡å¼ | 10-30åˆ†é’Ÿ |

**æ³¨**: ä½¿ç”¨ `use_llm_validation=True` ä¼šå¢åŠ 3-10å€æ—¶é—´

---

## ğŸ“ æ ¸å¿ƒåŸåˆ™ï¼ˆä¸“ä¸šè§†è§’ï¼‰

### 1. å®ä½“ç­‰ä»·æ€§åˆ¤å®š

```
ä¸¤ä¸ªheadèŠ‚ç‚¹ç­‰ä»· âŸº æŒ‡ä»£åŒä¸€çœŸå®ä¸–ç•Œå¯¹è±¡

åˆ¤å®šä¾æ®ï¼š
âœ“ æŒ‡ç§°ä¸€è‡´æ€§ (Referential Identity)
âœ“ æ›¿æ¢æµ‹è¯• (Substitutability Test)  
âœ“ å±æ€§ä¸€è‡´æ€§ (Property Consistency)
```

### 2. ä¿å®ˆæ€§åŸåˆ™

```
é”™è¯¯æˆæœ¬ä¸å¯¹ç­‰ï¼š
  False Merge (é”™è¯¯åˆå¹¶) >> False Split (é”™è¯¯åˆ†ç¦»)

ç­–ç•¥ï¼š
  ä¸ç¡®å®šæ—¶ â†’ ä¿æŒåˆ†ç¦»
  ç½®ä¿¡åº¦é˜ˆå€¼ â†’ ä¸¥æ ¼è®¾å®š
```

### 3. å¯è§£é‡Šæ€§

æ¯æ¬¡åˆå¹¶éƒ½è®°å½•ï¼š
- ä¸ºä»€ä¹ˆåˆå¹¶ï¼Ÿï¼ˆrationaleï¼‰
- ç½®ä¿¡åº¦å¤šå°‘ï¼Ÿï¼ˆconfidenceï¼‰
- ä½¿ç”¨ä»€ä¹ˆæ–¹æ³•ï¼Ÿï¼ˆmethod: exact/embedding/llmï¼‰
- ä½•æ—¶åˆå¹¶çš„ï¼Ÿï¼ˆtimestampï¼‰

---

## ğŸ” æ•ˆæœéªŒè¯

### æŸ¥çœ‹åˆå¹¶ç»“æœ

```python
# æ£€æŸ¥å“ªäº›èŠ‚ç‚¹è¢«åˆå¹¶äº†
for node_id, data in builder.graph.nodes(data=True):
    dedup_info = data.get("properties", {}).get("head_dedup", {})
    
    if dedup_info and dedup_info.get("merged_nodes"):
        print(f"\nâœ“ {node_id} ({data['properties']['name']})")
        print(f"  Merged: {len(dedup_info['merged_nodes'])} nodes")
        
        for record in dedup_info["merge_history"]:
            print(f"    â€¢ {record['merged_node_name']}")
            print(f"      Confidence: {record['confidence']:.2f}")
            print(f"      Rationale: {record['rationale'][:80]}...")
```

### å¯¼å‡ºäººå·¥å®¡æ ¸

```python
# å¯¼å‡ºä¸­ç­‰ç½®ä¿¡åº¦çš„åˆå¹¶ä¾›å®¡æ ¸
builder.export_head_merge_candidates_for_review(
    output_path="output/review/head_merges.csv",
    min_confidence=0.70,
    max_confidence=0.90
)

# åœ¨Excelä¸­æ‰“å¼€ head_merges.csvï¼Œæ£€æŸ¥åˆå¹¶æ˜¯å¦æ­£ç¡®
```

---

## â“ å¸¸è§é—®é¢˜é€ŸæŸ¥

| é—®é¢˜ | å¿«é€Ÿè§£å†³ |
|------|----------|
| **å¤„ç†å¤ªæ…¢** | é™ä½ `max_candidates`ï¼Œæé«˜ `threshold`ï¼Œç¦ç”¨ `use_llm` |
| **åˆå¹¶é”™è¯¯** | æé«˜ `threshold` åˆ° 0.90+ï¼Œå¯ç”¨ `use_llm=True` |
| **æ¼æ‰é‡å¤** | é™ä½ `threshold` åˆ° 0.80ï¼Œä½†è¦äººå·¥å®¡æ ¸ |
| **å†…å­˜æº¢å‡º** | å‡å°‘ `max_candidates`ï¼Œæˆ–å®ç°åˆ†æ‰¹å¤„ç† |
| **æƒ³è¦å®¡æ ¸** | è®¾ç½® `export_review=True` |

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

### ç†è®ºåŸºç¡€

- **Entity Resolution**: æ•°æ®é›†æˆä¸­çš„å®ä½“è§£ææŠ€æœ¯
- **Coreference Resolution**: NLPä¸­çš„å…±æŒ‡æ¶ˆè§£
- **Entity Linking**: çŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“é“¾æ¥

### ç›¸å…³è®ºæ–‡

- DeepER: Deep Learning for Entity Resolution
- Neural Coreference Resolution (Clark & Manning, 2016)
- GraphER: Entity Resolution in Knowledge Graphs

---

## ğŸ‰ å¼€å§‹ä½¿ç”¨

æ‚¨ç°åœ¨å·²ç»äº†è§£äº†headå»é‡çš„æ ¸å¿ƒæ–¹æ¡ˆï¼Œå¯ä»¥ï¼š

1. âœ… æŸ¥çœ‹ `HEAD_DEDUP_IMPLEMENTATION_GUIDE.md` è¿›è¡Œè¯¦ç»†é›†æˆ
2. âœ… å‚è€ƒ `head_deduplication_reference.py` ä¸­çš„ä»£ç å®ç°
3. âœ… è¿è¡Œ `example_head_deduplication.py` ä¸­çš„ç¤ºä¾‹
4. âœ… é˜…è¯» `HEAD_DEDUPLICATION_SOLUTION.md` äº†è§£è®¾è®¡ç»†èŠ‚

**ç¥æ‚¨å®æ–½é¡ºåˆ©ï¼**

---

**ç‰ˆæœ¬**: v1.0  
**æ—¥æœŸ**: 2025-10-27  
**ä½œè€…**: Knowledge Graph Architect
