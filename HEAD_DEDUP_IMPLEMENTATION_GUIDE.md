# HeadèŠ‚ç‚¹å»é‡å®æ–½æŒ‡å—

**ç‰ˆæœ¬**: v1.0  
**æ—¥æœŸ**: 2025-10-27  
**ç›®æ ‡**: å¿«é€Ÿå°†headèŠ‚ç‚¹å»é‡åŠŸèƒ½é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

---

## ğŸ“‹ å¿«é€Ÿå¯¼èˆª

- [é›†æˆæ­¥éª¤](#é›†æˆæ­¥éª¤) - 5æ­¥å®Œæˆé›†æˆ
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜) - å‚æ•°è°ƒä¼˜æŒ‡å—
- [æµ‹è¯•éªŒè¯](#æµ‹è¯•éªŒè¯) - ç¡®ä¿åŠŸèƒ½æ­£å¸¸
- [æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜) - å¤§è§„æ¨¡å›¾è°±ä¼˜åŒ–
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜) - æ•…éšœæ’é™¤

---

## é›†æˆæ­¥éª¤

### Step 1: æ·»åŠ Mixinç±»åˆ°kt_gen.py

```bash
# æ–¹æ³•1: ç›´æ¥åˆå¹¶ä»£ç 
# å°† head_deduplication_reference.py ä¸­çš„ä»£ç æ·»åŠ åˆ° models/constructor/kt_gen.py

# æ–¹æ³•2: ä½¿ç”¨Mixinï¼ˆæ¨èï¼‰
# åœ¨ kt_gen.py ä¸­å¯¼å…¥å¹¶ç»§æ‰¿
```

**ä¿®æ”¹ `models/constructor/kt_gen.py`**:

```python
# æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from head_deduplication_reference import HeadDeduplicationMixin

# ä¿®æ”¹ç±»å®šä¹‰
class KnowledgeTreeGen(HeadDeduplicationMixin, ...):
    """
    ç°åœ¨ KnowledgeTreeGen å…·æœ‰ä»¥ä¸‹æ–°æ–¹æ³•ï¼š
    - deduplicate_heads()
    - validate_graph_integrity_after_head_dedup()
    - export_head_merge_candidates_for_review()
    """
    pass
```

### Step 2: æ·»åŠ é…ç½®é¡¹

**ä¿®æ”¹ `config/base_config.yaml`**:

```yaml
# åœ¨semantic_dedupéƒ¨åˆ†æ·»åŠ head_dedupé…ç½®
semantic_dedup:
  # ... ç°æœ‰é…ç½® ...
  
  # HeadèŠ‚ç‚¹å»é‡é…ç½®
  head_dedup:
    enabled: true                     # æ˜¯å¦å¯ç”¨headå»é‡
    enable_semantic: true             # æ˜¯å¦å¯ç”¨è¯­ä¹‰å»é‡
    similarity_threshold: 0.85        # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰
    use_llm_validation: false         # æ˜¯å¦ä½¿ç”¨LLMéªŒè¯ï¼ˆæ…¢ä½†å‡†ï¼‰
    max_candidates: 1000              # æœ€å¤§å¤„ç†å€™é€‰å¯¹æ•°é‡
    export_review: false              # æ˜¯å¦å¯¼å‡ºå®¡æ ¸æ–‡ä»¶
    review_confidence_range: [0.70, 0.90]  # å®¡æ ¸ç½®ä¿¡åº¦åŒºé—´
```

### Step 3: åœ¨Pipelineä¸­è°ƒç”¨

**ä¿®æ”¹ä¸»å¤„ç†æµç¨‹** (ä¾‹å¦‚åœ¨ `main.py` æˆ–å¤„ç†å®Œæˆå):

```python
def build_knowledge_graph(documents, config):
    """æ„å»ºçŸ¥è¯†å›¾è°±çš„å®Œæ•´æµç¨‹"""
    
    # 1. åˆ›å»ºæ„å»ºå™¨
    builder = KnowledgeTreeGen(dataset_name="demo", config=config)
    
    # 2. å¤„ç†æ–‡æ¡£
    for doc in documents:
        builder.process_document(doc)
    
    # 3. æ‰§è¡Œtailå»é‡ï¼ˆç°æœ‰åŠŸèƒ½ï¼‰
    if config.semantic_dedup.enabled:
        builder.triple_deduplicate_semantic()
    
    # 4. ã€æ–°å¢ã€‘æ‰§è¡Œheadå»é‡
    if config.semantic_dedup.head_dedup.enabled:
        head_dedup_config = config.semantic_dedup.head_dedup
        
        stats = builder.deduplicate_heads(
            enable_semantic=head_dedup_config.enable_semantic,
            similarity_threshold=head_dedup_config.similarity_threshold,
            use_llm_validation=head_dedup_config.use_llm_validation,
            max_candidates=head_dedup_config.max_candidates
        )
        
        logger.info(f"Head deduplication: merged {stats['total_merges']} nodes")
        
        # å¯é€‰ï¼šå¯¼å‡ºäººå·¥å®¡æ ¸
        if head_dedup_config.export_review:
            review_path = f"output/review/head_merge_{time.time()}.csv"
            builder.export_head_merge_candidates_for_review(
                output_path=review_path,
                min_confidence=head_dedup_config.review_confidence_range[0],
                max_confidence=head_dedup_config.review_confidence_range[1]
            )
    
    # 5. ä¿å­˜å›¾è°±
    builder.save_graph("output/graphs/final_graph.graphml")
    
    return builder
```

### Step 4: æ·»åŠ ä¾èµ–ï¼ˆå¦‚æœéœ€è¦ï¼‰

æ£€æŸ¥ `requirements.txt` æ˜¯å¦åŒ…å«ä»¥ä¸‹ä¾èµ–:

```txt
# å·²æœ‰çš„ä¾èµ–
networkx>=2.8
numpy>=1.21
tiktoken>=0.3
json-repair>=0.7

# è¯­ä¹‰å»é‡éœ€è¦
scikit-learn>=1.0  # ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
```

å¦‚æœç¼ºå°‘ï¼Œæ·»åŠ å¹¶å®‰è£…:

```bash
pip install scikit-learn>=1.0
```

### Step 5: éªŒè¯é›†æˆ

è¿è¡Œç®€å•æµ‹è¯•:

```python
# test_head_dedup_integration.py
from models.constructor.kt_gen import KnowledgeTreeGen

def test_integration():
    builder = KnowledgeTreeGen(dataset_name="test")
    
    # æ£€æŸ¥æ–¹æ³•æ˜¯å¦å¯ç”¨
    assert hasattr(builder, 'deduplicate_heads')
    assert hasattr(builder, 'validate_graph_integrity_after_head_dedup')
    assert hasattr(builder, 'export_head_merge_candidates_for_review')
    
    print("âœ“ Integration successful!")

if __name__ == "__main__":
    test_integration()
```

---

## é…ç½®è¯´æ˜

### å‚æ•°è¯¦è§£

#### `enabled` (bool)
- **é»˜è®¤å€¼**: `true`
- **è¯´æ˜**: æ˜¯å¦å¯ç”¨headå»é‡
- **å»ºè®®**: æ€»æ˜¯å¯ç”¨ï¼Œå¯æ˜¾è‘—å‡å°‘å†—ä½™èŠ‚ç‚¹

#### `enable_semantic` (bool)
- **é»˜è®¤å€¼**: `true`
- **è¯´æ˜**: æ˜¯å¦å¯ç”¨è¯­ä¹‰å»é‡ï¼ˆç²¾ç¡®åŒ¹é…å§‹ç»ˆæ‰§è¡Œï¼‰
- **æƒè¡¡**:
  - `true`: æ›´é«˜å¬å›ç‡ï¼Œè¯†åˆ«æ›´å¤šç­‰ä»·èŠ‚ç‚¹
  - `false`: æ›´å¿«é€Ÿåº¦ï¼Œä»…å¤„ç†å®Œå…¨ç›¸åŒçš„åç§°

#### `similarity_threshold` (float, 0.0-1.0)
- **é»˜è®¤å€¼**: `0.85`
- **è¯´æ˜**: è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
- **å»ºè®®**:
  - `0.90-0.95`: é«˜ç²¾åº¦æ¨¡å¼ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ
  - `0.85-0.90`: å¹³è¡¡æ¨¡å¼ï¼Œæ¨èé»˜è®¤
  - `0.70-0.85`: é«˜å¬å›æ¨¡å¼ï¼Œé€‚åˆæ¢ç´¢æ€§åˆ†æ
- **æ³¨æ„**: é˜ˆå€¼è¶Šä½ï¼Œå¬å›ç‡è¶Šé«˜ä½†è¯¯åˆå¹¶é£é™©è¶Šå¤§

#### `use_llm_validation` (bool)
- **é»˜è®¤å€¼**: `false`
- **è¯´æ˜**: æ˜¯å¦ä½¿ç”¨LLMè¿›è¡ŒäºŒæ¬¡éªŒè¯
- **æƒè¡¡**:
  - `true`: æœ€é«˜å‡†ç¡®ç‡ï¼Œä½†é€Ÿåº¦æ…¢ã€æˆæœ¬é«˜
  - `false`: ä»…ç”¨embeddingï¼Œå¿«é€Ÿä½†å¯èƒ½ä¸å¤Ÿç²¾ç¡®
- **å»ºè®®**: 
  - ç”Ÿäº§ç¯å¢ƒé¦–æ¬¡è¿è¡Œ: `true`
  - æ—¥å¸¸å¢é‡æ›´æ–°: `false`

#### `max_candidates` (int)
- **é»˜è®¤å€¼**: `1000`
- **è¯´æ˜**: æœ€å¤§å¤„ç†çš„å€™é€‰å¯¹æ•°é‡
- **å»ºè®®**:
  - å°å›¾è°±(< 1kèŠ‚ç‚¹): `1000-5000`
  - ä¸­ç­‰å›¾è°±(1k-10kèŠ‚ç‚¹): `500-1000`
  - å¤§å›¾è°±(> 10kèŠ‚ç‚¹): `200-500`
- **æ³¨æ„**: å½±å“LLMæˆæœ¬å’Œå¤„ç†æ—¶é—´

#### `export_review` (bool)
- **é»˜è®¤å€¼**: `false`
- **è¯´æ˜**: æ˜¯å¦å¯¼å‡ºä¸­ç­‰ç½®ä¿¡åº¦æ¡ˆä¾‹ä¾›äººå·¥å®¡æ ¸
- **å»ºè®®**: ç”Ÿäº§ç¯å¢ƒé¦–æ¬¡è¿è¡Œæ—¶è®¾ä¸º `true`

#### `review_confidence_range` (list[float, float])
- **é»˜è®¤å€¼**: `[0.70, 0.90]`
- **è¯´æ˜**: éœ€è¦äººå·¥å®¡æ ¸çš„ç½®ä¿¡åº¦åŒºé—´
- **é€»è¾‘**:
  - `< 0.70`: è‡ªåŠ¨æ‹’ç»åˆå¹¶
  - `0.70-0.90`: å¯¼å‡ºå®¡æ ¸
  - `> 0.90`: è‡ªåŠ¨æ¥å—åˆå¹¶

---

## æµ‹è¯•éªŒè¯

### å•å…ƒæµ‹è¯•

åˆ›å»º `test_head_deduplication.py`:

```python
import unittest
from models.constructor.kt_gen import KnowledgeTreeGen

class TestHeadDeduplication(unittest.TestCase):
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.builder = KnowledgeTreeGen(dataset_name="test")
        
        # æ·»åŠ æµ‹è¯•æ•°æ®
        self.builder.graph.add_node("entity_0", label="entity", properties={"name": "åŒ—äº¬"})
        self.builder.graph.add_node("entity_1", label="entity", properties={"name": "åŒ—äº¬å¸‚"})
        self.builder.graph.add_node("entity_2", label="entity", properties={"name": "ä¸Šæµ·"})
    
    def test_exact_match_dedup(self):
        """æµ‹è¯•ç²¾ç¡®åŒ¹é…å»é‡"""
        candidates = ["entity_0", "entity_1", "entity_2"]
        merge_mapping = self.builder._deduplicate_heads_exact(candidates)
        
        # åŒ—äº¬å’ŒåŒ—äº¬å¸‚åº”è¯¥è¢«æ ‡å‡†åŒ–ä¸ºåŒä¸€åç§°
        self.assertGreaterEqual(len(merge_mapping), 0)
    
    def test_merge_preserves_edges(self):
        """æµ‹è¯•åˆå¹¶ä¿æŒè¾¹çš„å®Œæ•´æ€§"""
        # æ·»åŠ è¾¹
        self.builder.graph.add_edge("entity_0", "entity_2", relation="nearby")
        
        # æ‰§è¡Œåˆå¹¶
        stats = self.builder.deduplicate_heads(enable_semantic=False)
        
        # éªŒè¯è¾¹ä»ç„¶å­˜åœ¨
        self.assertTrue(self.builder.graph.has_edge("entity_0", "entity_2") or 
                       self.builder.graph.has_edge("entity_1", "entity_2"))
    
    def test_integrity_validation(self):
        """æµ‹è¯•å®Œæ•´æ€§éªŒè¯"""
        stats = self.builder.deduplicate_heads(enable_semantic=False)
        issues = self.builder.validate_graph_integrity_after_head_dedup()
        
        # ä¸åº”è¯¥æœ‰æ‚¬ç©ºå¼•ç”¨
        self.assertEqual(len(issues["dangling_references"]), 0)

if __name__ == "__main__":
    unittest.main()
```

è¿è¡Œæµ‹è¯•:

```bash
python test_head_deduplication.py -v
```

### é›†æˆæµ‹è¯•

ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•:

```python
# test_integration_real_data.py
from models.constructor.kt_gen import KnowledgeTreeGen

def test_with_real_data():
    """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•å®Œæ•´æµç¨‹"""
    
    # 1. æ„å»ºå›¾è°±
    builder = KnowledgeTreeGen(dataset_name="demo")
    
    documents = [
        {"text": "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½ï¼Œä½äºååŒ—åœ°åŒºã€‚", "id": 1},
        {"text": "åŒ—äº¬å¸‚æ˜¯ä¸­åäººæ°‘å…±å’Œå›½çš„é¦–éƒ½ã€‚", "id": 2},
        {"text": "Beijing is the capital of China.", "id": 3},
        {"text": "ä¸Šæµ·æ˜¯ä¸­å›½æœ€å¤§çš„åŸå¸‚ã€‚", "id": 4}
    ]
    
    for doc in documents:
        builder.process_document(doc)
    
    print(f"Initial entities: {len([n for n, d in builder.graph.nodes(data=True) if d.get('label') == 'entity'])}")
    
    # 2. æ‰§è¡Œheadå»é‡
    stats = builder.deduplicate_heads(
        enable_semantic=True,
        similarity_threshold=0.85,
        use_llm_validation=False
    )
    
    print(f"Final entities: {stats['final_entity_count']}")
    print(f"Merged: {stats['total_merges']}")
    
    # 3. éªŒè¯ç»“æœ
    assert stats['final_entity_count'] < len([n for n, d in builder.graph.nodes(data=True) if d.get('label') == 'entity'])
    
    # 4. æ£€æŸ¥å®Œæ•´æ€§
    issues = builder.validate_graph_integrity_after_head_dedup()
    assert not any(issues.values()), f"Integrity issues found: {issues}"
    
    print("âœ“ Integration test passed!")

if __name__ == "__main__":
    test_with_real_data()
```

---

## æ€§èƒ½è°ƒä¼˜

### åœºæ™¯1: å°å›¾è°± (< 1kå®ä½“)

```yaml
head_dedup:
  enabled: true
  enable_semantic: true
  similarity_threshold: 0.85
  use_llm_validation: true   # å¯ä»¥æ‰¿å—LLMæˆæœ¬
  max_candidates: 5000
```

**é¢„æœŸæ€§èƒ½**: < 10ç§’

### åœºæ™¯2: ä¸­ç­‰å›¾è°± (1k-10kå®ä½“)

```yaml
head_dedup:
  enabled: true
  enable_semantic: true
  similarity_threshold: 0.87
  use_llm_validation: false  # ä½¿ç”¨embeddingåŠ é€Ÿ
  max_candidates: 1000
```

**é¢„æœŸæ€§èƒ½**: 30ç§’ - 2åˆ†é’Ÿ

### åœºæ™¯3: å¤§å›¾è°± (> 10kå®ä½“)

```yaml
head_dedup:
  enabled: true
  enable_semantic: true
  similarity_threshold: 0.90  # æ›´ä¸¥æ ¼ï¼Œå‡å°‘å€™é€‰å¯¹
  use_llm_validation: false
  max_candidates: 500
```

**ä¼˜åŒ–ç­–ç•¥**:

1. **åˆ†æ‰¹å¤„ç†**:
```python
# å°†èŠ‚ç‚¹åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
batch_size = 1000
candidates = builder._collect_head_candidates()
for i in range(0, len(candidates), batch_size):
    batch = candidates[i:i+batch_size]
    # å¯¹æ¯æ‰¹ç‹¬ç«‹å»é‡
```

2. **ä½¿ç”¨ç¼“å­˜**:
```python
# åœ¨head_deduplication_reference.pyä¸­å·²åŒ…å«ç¼“å­˜è£…é¥°å™¨
@lru_cache(maxsize=10000)
def _describe_node_cached(self, node_id: str) -> str:
    return self._describe_node(node_id)
```

3. **å¹¶å‘embeddingè®¡ç®—**:
```python
# æ‰¹é‡è·å–embeddingï¼Œåˆ©ç”¨GPUåŠ é€Ÿ
embeddings = self._batch_get_embeddings(descriptions)
```

**é¢„æœŸæ€§èƒ½**: 5-30åˆ†é’Ÿï¼ˆå–å†³äºç¡¬ä»¶ï¼‰

### å†…å­˜ä¼˜åŒ–

å¦‚æœé‡åˆ°å†…å­˜é—®é¢˜:

1. **å‡å°‘max_candidates**:
```yaml
max_candidates: 200  # ä»1000é™ä½åˆ°200
```

2. **æé«˜similarity_threshold**:
```yaml
similarity_threshold: 0.92  # ä»0.85æé«˜åˆ°0.92
```

3. **ç¦ç”¨éƒ¨åˆ†ç‰¹æ€§**:
```yaml
enable_semantic: false  # ä»…ç²¾ç¡®åŒ¹é…
```

---

## å¸¸è§é—®é¢˜

### Q1: åˆå¹¶äº†ä¸åº”è¯¥åˆå¹¶çš„èŠ‚ç‚¹æ€ä¹ˆåŠï¼Ÿ

**A**: æœ‰å‡ ä¸ªè§£å†³æ–¹æ¡ˆ:

1. **æé«˜é˜ˆå€¼**:
```yaml
similarity_threshold: 0.90  # ä»0.85æé«˜
```

2. **å¯ç”¨äººå·¥å®¡æ ¸**:
```yaml
export_review: true
review_confidence_range: [0.70, 0.95]  # æ‰©å¤§å®¡æ ¸èŒƒå›´
```

3. **ä½¿ç”¨LLMéªŒè¯**:
```yaml
use_llm_validation: true
```

4. **å›æ»šæœºåˆ¶**ï¼ˆéœ€è¦å®ç°ï¼‰:
```python
# ä¿å­˜å»é‡å‰çš„å¿«ç…§
builder.save_graph("backup_before_dedup.graphml")

# å¦‚æœå‡ºé—®é¢˜ï¼Œå¯ä»¥é‡æ–°åŠ è½½
builder.load_graph("backup_before_dedup.graphml")
```

### Q2: å¤„ç†é€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: å‚è€ƒ[æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜)éƒ¨åˆ†ï¼Œå…³é”®ä¼˜åŒ–:

- é™ä½ `max_candidates`
- ç¦ç”¨ `use_llm_validation`
- æé«˜ `similarity_threshold`ï¼ˆå‡å°‘å€™é€‰å¯¹ï¼‰

### Q3: å¦‚ä½•å¤„ç†ç‰¹å®šé¢†åŸŸçš„å®ä½“ï¼Ÿ

**A**: æ‰©å±• `_normalize_entity_name` æ–¹æ³•:

```python
def _normalize_entity_name(self, name: str) -> str:
    normalized = super()._normalize_entity_name(name)
    
    # æ·»åŠ é¢†åŸŸç‰¹å®šè§„åˆ™
    # ä¾‹å¦‚ï¼šäººåå¤„ç†
    if self.dataset_name == "person_names":
        # å»é™¤ç§°å‘¼ï¼ˆå…ˆç”Ÿã€å¥³å£«ã€åšå£«ç­‰ï¼‰
        for title in ["å…ˆç”Ÿ", "å¥³å£«", "åšå£«", "æ•™æˆ"]:
            normalized = normalized.replace(title, "").strip()
    
    return normalized
```

### Q4: å¦‚ä½•è¯„ä¼°å»é‡æ•ˆæœï¼Ÿ

**A**: ä½¿ç”¨ä»¥ä¸‹æŒ‡æ ‡:

1. **Reduction Rate**ï¼ˆå‡å°‘ç‡ï¼‰:
```python
reduction_rate = (initial_count - final_count) / initial_count * 100
```

2. **Precision**ï¼ˆç²¾ç¡®ç‡ï¼‰:
æ‰‹å·¥æ ‡æ³¨éƒ¨åˆ†ç»“æœï¼Œè®¡ç®—æ­£ç¡®åˆå¹¶æ¯”ä¾‹

3. **Recall**ï¼ˆå¬å›ç‡ï¼‰:
æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ˜æ˜¾çš„é‡å¤èŠ‚ç‚¹æœªè¢«åˆå¹¶

4. **Graph Density**ï¼ˆå›¾å¯†åº¦ï¼‰:
```python
# å»é‡åå¹³å‡åº¦æ•°åº”è¯¥å¢åŠ ï¼ˆå› ä¸ºè¾¹è¢«åˆå¹¶åˆ°æ›´å°‘çš„èŠ‚ç‚¹ä¸Šï¼‰
avg_degree_before = ...
avg_degree_after = ...
density_increase = avg_degree_after / avg_degree_before
```

### Q5: å¦‚ä½•å¤„ç†æ­§ä¹‰å®ä½“ï¼Ÿ

**A**: ä¾‹å¦‚"è‹¹æœ"å¯èƒ½æ˜¯æ°´æœæˆ–å…¬å¸:

1. **åˆ©ç”¨ä¸Šä¸‹æ–‡**:
```python
def _collect_node_context(self, node_id: str, max_relations: int = 10):
    # æ”¶é›†èŠ‚ç‚¹çš„å…³ç³»å’Œå±æ€§ï¼Œç”¨äºLLMåˆ¤æ–­
    # ä¾‹å¦‚ï¼š"è‹¹æœ-has_attribute-æ°´æœ" vs "è‹¹æœ-founded-1976"
```

2. **ä½¿ç”¨schemaç±»å‹**:
```python
# æ£€æŸ¥entity_type
entity_type_1 = self.graph.nodes[node_id_1].get("properties", {}).get("schema_type")
entity_type_2 = self.graph.nodes[node_id_2].get("properties", {}).get("schema_type")

if entity_type_1 != entity_type_2:
    # ä¸åŒç±»å‹ï¼Œä¸åˆå¹¶
    return False
```

3. **ä¿å®ˆç­–ç•¥**:
```yaml
similarity_threshold: 0.95  # éå¸¸é«˜çš„é˜ˆå€¼ï¼Œåªåˆå¹¶æ˜ç¡®çš„
```

---

## ä¸‹ä¸€æ­¥

å®Œæˆé›†æˆåï¼Œå»ºè®®:

1. âœ… åœ¨å°è§„æ¨¡æµ‹è¯•æ•°æ®ä¸ŠéªŒè¯åŠŸèƒ½
2. âœ… è°ƒæ•´å‚æ•°ï¼Œæ‰¾åˆ°æœ€ä½³é…ç½®
3. âœ… åœ¨ä¸­ç­‰è§„æ¨¡æ•°æ®ä¸Šæµ‹è¯•æ€§èƒ½
4. âœ… å¯¼å‡ºå®¡æ ¸æ¡ˆä¾‹ï¼Œäººå·¥è¯„ä¼°è´¨é‡
5. âœ… éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼Œç›‘æ§æ•ˆæœ

---

## é™„å½•

### å®Œæ•´é…ç½®ç¤ºä¾‹

```yaml
# config/production_config.yaml
semantic_dedup:
  enabled: true
  
  # Tailå»é‡é…ç½®ï¼ˆç°æœ‰ï¼‰
  similarity_threshold: 0.85
  clustering_method: "embedding"
  # ... å…¶ä»–tailå»é‡é…ç½® ...
  
  # Headå»é‡é…ç½®ï¼ˆæ–°å¢ï¼‰
  head_dedup:
    enabled: true
    enable_semantic: true
    similarity_threshold: 0.87
    use_llm_validation: false
    max_candidates: 1000
    export_review: true
    review_confidence_range: [0.70, 0.90]
    review_output_dir: "output/review"
```

### æ—¥å¿—é…ç½®å»ºè®®

```python
# åœ¨è¿è¡Œheadå»é‡æ—¶ï¼Œè®¾ç½®è¯¦ç»†æ—¥å¿—
import logging
logging.getLogger('models.constructor.kt_gen').setLevel(logging.DEBUG)
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-27  
**ç»´æŠ¤è€…**: Knowledge Graph Team
