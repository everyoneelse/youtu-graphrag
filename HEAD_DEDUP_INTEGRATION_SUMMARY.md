# HeadèŠ‚ç‚¹å»é‡åŠŸèƒ½é›†æˆæ€»ç»“

**æ—¥æœŸ**: 2025-10-27  
**åŠŸèƒ½**: HeadèŠ‚ç‚¹å…¨å±€å»é‡  
**çŠ¶æ€**: âœ… å·²é›†æˆåˆ°ä»£ç åº“

---

## ğŸ“¦ ä¿®æ”¹æ–‡ä»¶æ¸…å•

### 1. é…ç½®æ–‡ä»¶
- **æ–‡ä»¶**: `config/base_config.yaml`
- **ä¿®æ”¹å†…å®¹**:
  - âœ… åœ¨ `construction.semantic_dedup` ä¸‹æ·»åŠ  `head_dedup` é…ç½®èŠ‚
  - âœ… åœ¨ `prompts` ä¸‹æ·»åŠ  `head_dedup.general` promptæ¨¡æ¿

### 2. æ ¸å¿ƒå®ç°
- **æ–‡ä»¶**: `models/constructor/kt_gen.py`
- **æ·»åŠ **: çº¦700è¡Œä»£ç ï¼Œ14ä¸ªæ–°æ–¹æ³•
- **ä¿®æ”¹**: prompt**ä»…**ä»é…ç½®æ–‡ä»¶åŠ è½½ï¼Œæ— fallback

### 3. ä½¿ç”¨ç¤ºä¾‹
- **æ–‡ä»¶**: `example_use_head_dedup.py` (æ–°å»º)
- **å†…å®¹**: 7ä¸ªä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### 4. æ–‡æ¡£
- **æ–‡ä»¶**: `HEAD_DEDUP_PROMPT_CUSTOMIZATION.md` (æ–°å»º)
- **å†…å®¹**: Promptè‡ªå®šä¹‰æŒ‡å—

---

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
âœ… **ä¸¤é˜¶æ®µå»é‡**ï¼šç²¾ç¡®åŒ¹é… + è¯­ä¹‰ç›¸ä¼¼åº¦  
âœ… **åŒæ¨¡å¼æ”¯æŒ**ï¼šEmbeddingå¿«é€Ÿæ¨¡å¼ / LLMé«˜ç²¾åº¦æ¨¡å¼  
âœ… **å®Œæ•´æº¯æº**ï¼šè®°å½•æ‰€æœ‰åˆå¹¶å†å²å’Œä¾æ®  
âœ… **å›¾ç»“æ„å®‰å…¨**ï¼šè‡ªåŠ¨è½¬ç§»è¾¹ã€åˆå¹¶å±æ€§ã€éªŒè¯å®Œæ•´æ€§  
âœ… **äººå·¥å®¡æ ¸**ï¼šå¯¼å‡ºä¸­ç­‰ç½®ä¿¡åº¦æ¡ˆä¾‹ä¾›å®¡æ ¸  

### ä¸ç°æœ‰ä»£ç çš„å…¼å®¹æ€§
âœ… ä½¿ç”¨ç›¸åŒçš„é…ç½®ä½“ç³» (`config.construction.semantic_dedup`)  
âœ… å¤ç”¨ç°æœ‰çš„ `_concurrent_llm_calls` å¹¶å‘è°ƒç”¨  
âœ… å¤ç”¨ç°æœ‰çš„ `_batch_get_embeddings` æ‰¹é‡embedding  
âœ… å¤ç”¨ç°æœ‰çš„ `_describe_node` èŠ‚ç‚¹æè¿°æ–¹æ³•  
âœ… æ—¥å¿—é£æ ¼ä¸ç°æœ‰ä»£ç ä¸€è‡´  

---

## ğŸ“‹ ä½¿ç”¨æ–¹å¼

### æ–¹å¼1: ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰

**Step 1**: ç¼–è¾‘ `config/base_config.yaml`

```yaml
construction:
  semantic_dedup:
    enabled: true  # å…ˆå¯ç”¨tailå»é‡
    
    head_dedup:
      enabled: true                      # å¯ç”¨headå»é‡
      enable_semantic: true               # å¯ç”¨è¯­ä¹‰å»é‡
      similarity_threshold: 0.85          # ç›¸ä¼¼åº¦é˜ˆå€¼
      use_llm_validation: false           # false=å¿«é€Ÿï¼Œtrue=ç²¾ç¡®
      max_candidates: 1000                # æœ€å¤§å€™é€‰å¯¹æ•°é‡
      candidate_similarity_threshold: 0.75
      max_relations_context: 10
      export_review: false                # æ˜¯å¦å¯¼å‡ºå®¡æ ¸æ–‡ä»¶
      review_confidence_range: [0.70, 0.90]
      review_output_dir: "output/review"
```

**Step 2**: åœ¨ä»£ç ä¸­è°ƒç”¨

```python
from models.constructor.kt_gen import KnowledgeTreeGen
from config import get_config

config = get_config()
builder = KnowledgeTreeGen(dataset_name="demo", config=config)

# æ„å»ºå›¾è°±
builder.build_knowledge_graph("data/demo/demo_corpus.json")

# Tailå»é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
if config.construction.semantic_dedup.enabled:
    builder.triple_deduplicate_semantic()

# Headå»é‡ï¼ˆè‡ªåŠ¨è¯»å–é…ç½®ï¼‰
stats = builder.deduplicate_heads()

print(f"Merged {stats['total_merges']} head nodes")
```

### æ–¹å¼2: ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°

```python
# è¦†ç›–é…ç½®æ–‡ä»¶çš„å‚æ•°
stats = builder.deduplicate_heads(
    enable_semantic=True,
    similarity_threshold=0.90,  # æ›´ä¸¥æ ¼
    use_llm_validation=True,    # ä½¿ç”¨LLM
    max_candidates=500          # é™åˆ¶LLMè°ƒç”¨
)
```

---

## ğŸ”§ ä¸»è¦æ–¹æ³•è¯´æ˜

### 1. ä¸»å…¥å£æ–¹æ³•

```python
def deduplicate_heads(
    self,
    enable_semantic: bool = None,
    similarity_threshold: float = None,
    use_llm_validation: bool = None,
    max_candidates: int = None
) -> Dict[str, Any]:
    """
    ä¸»å…¥å£ï¼šæ‰§è¡ŒheadèŠ‚ç‚¹å»é‡
    
    Returns:
        {
            "enabled": True,
            "total_candidates": 100,
            "exact_merges": 10,
            "semantic_merges": 5,
            "total_merges": 15,
            "initial_entity_count": 100,
            "final_entity_count": 85,
            "reduction_rate": 15.0,
            "elapsed_time_seconds": 12.34,
            "integrity_issues": {...}
        }
    """
```

### 2. è¾…åŠ©æ–¹æ³•

| æ–¹æ³• | åŠŸèƒ½ |
|------|------|
| `_collect_head_candidates()` | æ”¶é›†æ‰€æœ‰entityèŠ‚ç‚¹ |
| `_deduplicate_heads_exact()` | ç²¾ç¡®åŒ¹é…å»é‡ |
| `_generate_semantic_candidates()` | ç”Ÿæˆè¯­ä¹‰å€™é€‰å¯¹ |
| `_validate_candidates_with_embedding()` | EmbeddingéªŒè¯ |
| `_validate_candidates_with_llm()` | LLMéªŒè¯ |
| `_merge_head_nodes()` | æ‰§è¡ŒèŠ‚ç‚¹åˆå¹¶ |
| `validate_graph_integrity_after_head_dedup()` | å®Œæ•´æ€§éªŒè¯ |
| `export_head_merge_candidates_for_review()` | å¯¼å‡ºå®¡æ ¸æ–‡ä»¶ |

---

## ğŸ“Š é…ç½®å‚æ•°è¯¦è§£

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `enabled` | bool | false | æ˜¯å¦å¯ç”¨headå»é‡ |
| `enable_semantic` | bool | true | æ˜¯å¦å¯ç”¨è¯­ä¹‰å»é‡ï¼ˆç²¾ç¡®åŒ¹é…æ€»æ˜¯æ‰§è¡Œï¼‰ |
| `similarity_threshold` | float | 0.85 | è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰ |
| `use_llm_validation` | bool | false | æ˜¯å¦ä½¿ç”¨LLMéªŒè¯ |
| `max_candidates` | int | 1000 | æœ€å¤§å€™é€‰å¯¹æ•°é‡ |
| `candidate_similarity_threshold` | float | 0.75 | é¢„ç­›é€‰ç›¸ä¼¼åº¦é˜ˆå€¼ |
| `max_relations_context` | int | 10 | ä¸Šä¸‹æ–‡ä¸­åŒ…å«çš„æœ€å¤§å…³ç³»æ•° |
| `export_review` | bool | false | æ˜¯å¦å¯¼å‡ºå®¡æ ¸æ–‡ä»¶ |
| `review_confidence_range` | list | [0.70, 0.90] | å®¡æ ¸ç½®ä¿¡åº¦åŒºé—´ |
| `review_output_dir` | string | "output/review" | å®¡æ ¸æ–‡ä»¶è¾“å‡ºç›®å½• |

### å‚æ•°è°ƒä¼˜å»ºè®®

#### å°å›¾è°± (< 1kå®ä½“)
```yaml
similarity_threshold: 0.85
use_llm_validation: true   # å¯ä»¥æ‰¿å—LLMæˆæœ¬
max_candidates: 5000
```

#### ä¸­ç­‰å›¾è°± (1k-10kå®ä½“)
```yaml
similarity_threshold: 0.87
use_llm_validation: false  # ä½¿ç”¨embeddingåŠ é€Ÿ
max_candidates: 1000
```

#### å¤§å›¾è°± (> 10kå®ä½“)
```yaml
similarity_threshold: 0.90  # æ›´ä¸¥æ ¼ï¼Œå‡å°‘å€™é€‰å¯¹
use_llm_validation: false
max_candidates: 500
```

---

## ğŸ¨ Promptè‡ªå®šä¹‰

### Promptä½ç½®

Headå»é‡çš„promptç°åœ¨å­˜å‚¨åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼š

**æ–‡ä»¶**: `config/base_config.yaml`  
**è·¯å¾„**: `prompts.head_dedup.general`

### å¯ç”¨å˜é‡

åœ¨promptä¸­å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å˜é‡ï¼š
- `{entity_1}` - ç¬¬ä¸€ä¸ªå®ä½“çš„æè¿°
- `{context_1}` - ç¬¬ä¸€ä¸ªå®ä½“çš„å…³ç³»ä¸Šä¸‹æ–‡
- `{entity_2}` - ç¬¬äºŒä¸ªå®ä½“çš„æè¿°
- `{context_2}` - ç¬¬äºŒä¸ªå®ä½“çš„å…³ç³»ä¸Šä¸‹æ–‡

### è‡ªå®šä¹‰ç¤ºä¾‹

ç¼–è¾‘ `config/base_config.yaml`:

```yaml
prompts:
  head_dedup:
    general: |-
      You are an expert in knowledge graph entity resolution.
      
      TASK: Determine if the following two entities refer to the SAME real-world object.
      
      Entity 1: {entity_1}
      Related knowledge about Entity 1:
      {context_1}
      
      Entity 2: {entity_2}
      Related knowledge about Entity 2:
      {context_2}
      
      # åœ¨è¿™é‡Œè‡ªå®šä¹‰ä½ çš„åˆ¤æ–­è§„åˆ™...
      # è¯¦è§ HEAD_DEDUP_PROMPT_CUSTOMIZATION.md
```

**è¯¦ç»†çš„Promptè‡ªå®šä¹‰æŒ‡å—**: è¯·å‚è€ƒ `HEAD_DEDUP_PROMPT_CUSTOMIZATION.md`

---

## ğŸ”„ å®Œæ•´Pipelineç¤ºä¾‹

```python
from models.constructor.kt_gen import KnowledgeTreeGen
from config import get_config

def build_complete_graph(corpus_path, dataset_name):
    """å®Œæ•´çš„çŸ¥è¯†å›¾è°±æ„å»ºæµç¨‹"""
    
    # 1. åˆå§‹åŒ–
    config = get_config()
    builder = KnowledgeTreeGen(dataset_name=dataset_name, config=config)
    
    # 2. æ„å»ºå›¾è°±
    print("Step 1: Building knowledge graph...")
    builder.build_knowledge_graph(corpus_path)
    
    # 3. Tailå»é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if config.construction.semantic_dedup.enabled:
        print("\nStep 2: Tail deduplication...")
        builder.triple_deduplicate_semantic()
    
    # 4. Headå»é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if hasattr(config.construction.semantic_dedup, 'head_dedup'):
        head_config = config.construction.semantic_dedup.head_dedup
        if getattr(head_config, 'enabled', False):
            print("\nStep 3: Head deduplication...")
            stats = builder.deduplicate_heads()
            
            print(f"\nâœ“ Head deduplication results:")
            print(f"  - Merged: {stats['total_merges']} nodes")
            print(f"  - Reduction: {stats['reduction_rate']:.1f}%")
            print(f"  - Time: {stats['elapsed_time_seconds']:.1f}s")
    
    # 5. ä¿å­˜æœ€ç»ˆå›¾è°±
    print("\nStep 4: Saving final graph...")
    output_path = f"output/graphs/{dataset_name}_final.graphml"
    builder.save_graphml(output_path)
    print(f"âœ“ Saved to {output_path}")
    
    return builder

# ä½¿ç”¨
builder = build_complete_graph(
    corpus_path="data/demo/demo_corpus.json",
    dataset_name="demo"
)
```

---

## ğŸ“ˆ æ€§èƒ½é¢„æœŸ

| å›¾è§„æ¨¡ | é…ç½® | é¢„æœŸæ—¶é—´ |
|--------|------|----------|
| 100å®ä½“ | å¹³è¡¡æ¨¡å¼ | < 5ç§’ |
| 1,000å®ä½“ | å¹³è¡¡æ¨¡å¼ | 10-30ç§’ |
| 10,000å®ä½“ | å¹³è¡¡æ¨¡å¼ | 1-5åˆ†é’Ÿ |
| 100,000å®ä½“ | å¹³è¡¡æ¨¡å¼ | 10-30åˆ†é’Ÿ |

**æ³¨**: ä½¿ç”¨ `use_llm_validation=True` ä¼šå¢åŠ 3-10å€æ—¶é—´

---

## ğŸ” æŸ¥çœ‹å»é‡ç»“æœ

### 1. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯

```python
stats = builder.deduplicate_heads()

print(f"Initial entities: {stats['initial_entity_count']}")
print(f"Final entities: {stats['final_entity_count']}")
print(f"Exact merges: {stats['exact_merges']}")
print(f"Semantic merges: {stats['semantic_merges']}")
print(f"Reduction rate: {stats['reduction_rate']:.2f}%")
```

### 2. æŸ¥çœ‹åˆå¹¶å†å²

```python
for node_id, data in builder.graph.nodes(data=True):
    if data.get("label") != "entity":
        continue
    
    dedup_info = data.get("properties", {}).get("head_dedup", {})
    
    if dedup_info and dedup_info.get("merged_nodes"):
        print(f"\nCanonical: {node_id}")
        print(f"  Name: {data['properties']['name']}")
        print(f"  Merged: {len(dedup_info['merged_nodes'])} nodes")
        
        for record in dedup_info["merge_history"]:
            print(f"    â€¢ {record['merged_node_name']}")
            print(f"      Confidence: {record['confidence']:.2f}")
            print(f"      Method: {record['method']}")
```

### 3. å¯¼å‡ºCSVå®¡æ ¸

```python
builder.export_head_merge_candidates_for_review(
    output_path="output/review/head_merges.csv",
    min_confidence=0.70,
    max_confidence=0.90
)
```

CSVæ ¼å¼ï¼š
```
canonical_node_id,canonical_name,merged_node_id,merged_name,confidence,method,rationale
entity_5,åŒ—äº¬,entity_10,åŒ—äº¬å¸‚,0.85,embedding,High embedding similarity...
entity_15,Apple Inc.,entity_20,Apple Company,0.88,llm,Both refer to the same...
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ‰§è¡Œé¡ºåº
```
âœ“ æ­£ç¡®é¡ºåº:
  1. æ„å»ºå›¾è°±
  2. Tailå»é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
  3. Headå»é‡
  4. ä¿å­˜å›¾è°±

âœ— é”™è¯¯é¡ºåº:
  - å…ˆHeadå»é‡åTailå»é‡ï¼ˆä¼šæœ‰é—®é¢˜ï¼‰
  - åœ¨å›¾è°±æ„å»ºä¸­é—´æ‰§è¡Œï¼ˆä¸å®Œæ•´ï¼‰
```

### 2. é…ç½®ä¾èµ–
```python
# Headå»é‡ä¾èµ–è¿™äº›ç°æœ‰åŠŸèƒ½ï¼š
- _batch_get_embeddings()      # éœ€è¦embeddingæ¨¡å‹
- _concurrent_llm_calls()       # å¦‚æœuse_llm_validation=True
- _describe_node()              # èŠ‚ç‚¹æè¿°
- _describe_node_for_clustering()  # ç®€åŒ–æè¿°
```

### 3. æ€§èƒ½è€ƒè™‘
- Embeddingæ¨¡å¼ï¼šO(nÂ²) ç›¸ä¼¼åº¦è®¡ç®—ï¼Œä½†æœ‰é¢„ç­›é€‰
- LLMæ¨¡å¼ï¼šæ›´æ…¢ä½†æ›´å‡†ï¼Œå»ºè®®é™åˆ¶ `max_candidates`
- å¤§å›¾è°±å»ºè®®åˆ†æ‰¹å¤„ç†æˆ–æé«˜é˜ˆå€¼

### 4. å›¾ç»“æ„å®‰å…¨
- æ‰€æœ‰è¾¹ä¼šè‡ªåŠ¨è½¬ç§»åˆ°canonicalèŠ‚ç‚¹
- é‡å¤è¾¹ä¼šè‡ªåŠ¨åˆå¹¶chunkä¿¡æ¯
- åˆ é™¤èŠ‚ç‚¹å‰ä¼šéªŒè¯å¼•ç”¨å®Œæ•´æ€§
- æ”¯æŒå®Œæ•´æ€§éªŒè¯æ–¹æ³•

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1: "Head deduplication is disabled in config"

**åŸå› **: é…ç½®æ–‡ä»¶ä¸­ `head_dedup.enabled = false`

**è§£å†³**:
```yaml
# config/base_config.yaml
head_dedup:
  enabled: true  # æ”¹ä¸ºtrue
```

### é—®é¢˜2: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å€™é€‰å¯¹

**å¯èƒ½åŸå› **:
- `candidate_similarity_threshold` å¤ªé«˜
- å®ä½“åç§°å¤ªä¸ç›¸ä¼¼
- Embeddingæ¨¡å‹é—®é¢˜

**è§£å†³**:
```yaml
candidate_similarity_threshold: 0.70  # é™ä½é˜ˆå€¼è¯•è¯•
```

### é—®é¢˜3: ImportError: scikit-learn

**åŸå› **: ç¼ºå°‘ä¾èµ–

**è§£å†³**:
```bash
pip install scikit-learn>=1.0
```

### é—®é¢˜4: åˆå¹¶äº†ä¸è¯¥åˆå¹¶çš„èŠ‚ç‚¹

**è§£å†³**:
1. æé«˜ `similarity_threshold` (å¦‚ 0.90)
2. å¯ç”¨ `use_llm_validation: true`
3. å¯¼å‡ºå®¡æ ¸æ–‡ä»¶äººå·¥æ£€æŸ¥

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

è¯¦ç»†è®¾è®¡å’ŒåŸç†è¯·å‚è€ƒï¼š
- `HEAD_DEDUPLICATION_SOLUTION.md` - å®Œæ•´æ–¹æ¡ˆè®¾è®¡
- `HEAD_DEDUP_LLM_CORE_LOGIC.md` - LLMåˆ¤æ–­é€»è¾‘è¯¦è§£
- `PROMPT_COMPARISON_HEAD_VS_TAIL_DEDUP.md` - ä¸tailå»é‡å¯¹æ¯”
- `PROFESSIONAL_EVALUATION_PROMPTS.md` - ä¸“ä¸šåº¦è¯„ä¼°
- `example_use_head_dedup.py` - ä½¿ç”¨ç¤ºä¾‹ä»£ç 

---

## âœ… æµ‹è¯•å»ºè®®

### å°è§„æ¨¡æµ‹è¯•
```python
# 1. å‡†å¤‡å°æ•°æ®é›†ï¼ˆ10-20ä¸ªæ–‡æ¡£ï¼‰
# 2. æ„å»ºå›¾è°±
# 3. æŸ¥çœ‹åˆå§‹å®ä½“æ•°é‡
# 4. æ‰§è¡Œheadå»é‡
# 5. æ£€æŸ¥ç»“æœæ˜¯å¦åˆç†
# 6. æŸ¥çœ‹åˆå¹¶å†å²
```

### éªŒè¯æ­£ç¡®æ€§
```python
# 1. è¿è¡Œå®Œæ•´æ€§éªŒè¯
issues = builder.validate_graph_integrity_after_head_dedup()
assert not any(issues.values()), f"Integrity issues: {issues}"

# 2. æ£€æŸ¥å›¾çš„åŸºæœ¬å±æ€§
assert builder.graph.number_of_nodes() > 0
assert builder.graph.number_of_edges() > 0

# 3. æŠ½æŸ¥å‡ ä¸ªåˆå¹¶ç»“æœ
# äººå·¥éªŒè¯æ˜¯å¦æ­£ç¡®
```

---

## ğŸ‰ æ€»ç»“

âœ… **å·²é›†æˆåŠŸèƒ½**ï¼š
- é…ç½®ç®¡ç†
- ç²¾ç¡®åŒ¹é…å»é‡
- è¯­ä¹‰ç›¸ä¼¼åº¦å»é‡ï¼ˆEmbeddingï¼‰
- LLMéªŒè¯ï¼ˆå¯é€‰ï¼‰
- å›¾ç»“æ„æ›´æ–°
- å®Œæ•´æ€§éªŒè¯
- äººå·¥å®¡æ ¸å¯¼å‡º

âœ… **ä»£ç è´¨é‡**ï¼š
- ä¸ç°æœ‰ä»£ç é£æ ¼ä¸€è‡´
- å®Œæ•´çš„é”™è¯¯å¤„ç†
- è¯¦ç»†çš„æ—¥å¿—è¾“å‡º
- ç±»å‹æç¤ºå®Œæ•´
- æ–‡æ¡£å­—ç¬¦ä¸²æ¸…æ™°

âœ… **å³ç”¨æ€§**ï¼š
- é…ç½®æ–‡ä»¶å¼€ç®±å³ç”¨
- æä¾›å¤šç§ä½¿ç”¨æ–¹å¼
- åŒ…å«å®Œæ•´ç¤ºä¾‹ä»£ç 
- è¯¦ç»†çš„ä½¿ç”¨æ–‡æ¡£

---

**é›†æˆçŠ¶æ€**: âœ… å®Œæˆ  
**æµ‹è¯•çŠ¶æ€**: â³ å¾…æµ‹è¯•  
**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæ•´  

**å»ºè®®ä¸‹ä¸€æ­¥**ï¼š
1. åœ¨å°è§„æ¨¡æ•°æ®ä¸Šæµ‹è¯•åŠŸèƒ½
2. æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´å‚æ•°
3. è€ƒè™‘æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–Prompt

---

**ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-27
