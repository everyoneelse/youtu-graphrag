# åˆ«åå»é‡æ”¹è¿›æ–¹æ¡ˆ - å®æ–½ææ¡ˆ

**æ—¥æœŸ**: 2025-10-31  
**ç›®æ ‡**: æ”¹è¿›Headå»é‡ï¼Œæ”¯æŒä½è¯­ä¹‰ç›¸ä¼¼åº¦çš„åˆ«åè¯†åˆ«  
**æ¡ˆä¾‹**: "å‰å¸ƒæ–¯ä¼ªå½±/æˆªæ–­ä¼ªå½±" ç­‰åˆ«åå¯¹

---

## ğŸ“‹ é—®é¢˜å›é¡¾

### å½“å‰å®ç°çš„å±€é™

```python
# å½“å‰çš„å€™é€‰ç”Ÿæˆé€»è¾‘ (kt_gen.py, line ~4617)
candidate_pairs = self._generate_semantic_candidates(
    remaining_nodes,
    max_candidates=max_candidates,
    similarity_threshold=candidate_similarity_threshold  # é»˜è®¤ 0.75
)
```

**é—®é¢˜**:
```
å®ä½“A: "å‰å¸ƒæ–¯ä¼ªå½±"
å®ä½“B: "æˆªæ–­ä¼ªå½±"

name_similarity = 0.65  # < 0.75é˜ˆå€¼
â†’ ä¸ä¼šç”Ÿæˆå€™é€‰å¯¹
â†’ å³ä½¿å›¾ä¸­æœ‰ A --[åˆ«ååŒ…æ‹¬]--> B
```

---

## ğŸ¯ æ”¹è¿›æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆé€‰æ‹©çŸ©é˜µ

| æ–¹æ¡ˆ | å®æ–½æˆæœ¬ | æ•ˆæœæå‡ | é£é™© | æ¨èé˜¶æ®µ |
|-----|---------|---------|-----|---------|
| **æ–¹æ¡ˆ1: æ˜¾å¼å…³ç³»ä¼˜å…ˆ** | â­ ä½ | â­â­â­â­â­ é«˜ | ä½ | **ç«‹å³** |
| **æ–¹æ¡ˆ2: å¤šç‰¹å¾èåˆ** | â­â­ ä¸­ | â­â­â­â­ è¾ƒé«˜ | ä¸­ | 1ä¸ªæœˆå†… |
| **æ–¹æ¡ˆ3: å­å›¾æè¿°** | â­â­â­ é«˜ | â­â­ æœ‰é™ | é«˜ | **ä¸æ¨è** |
| **æ–¹æ¡ˆ4: æœºå™¨å­¦ä¹ ** | â­â­â­â­ å¾ˆé«˜ | â­â­â­â­â­ é«˜ | ä¸­ | 3ä¸ªæœˆå |

### è¯¦ç»†è¯„ä¼°

#### æ–¹æ¡ˆ1: æ˜¾å¼å…³ç³»ä¼˜å…ˆ â­â­â­â­â­ **å¼ºçƒˆæ¨è**

**æ ¸å¿ƒé€»è¾‘**:
```python
# ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šä»å›¾ä¸­æå–æ˜¾å¼åˆ«åå…³ç³»
if graph.has_edge(A, B, relation="åˆ«ååŒ…æ‹¬"):
    candidate_pairs.append((A, B, 0.95, 'explicit_alias'))
```

**ä¼˜ç‚¹**:
- âœ… **ç²¾å‡†**: ç›´æ¥åˆ©ç”¨äººå·¥æ ‡æ³¨çš„çŸ¥è¯†
- âœ… **ç®€å•**: ä»£ç æ”¹åŠ¨å°‘ï¼ˆ~30è¡Œï¼‰
- âœ… **å¿«é€Ÿ**: O(E) éå†è¾¹ï¼Œæ— é¢å¤–è®¡ç®—
- âœ… **å¯è§£é‡Š**: æ˜ç¡®æ¥æºäºå“ªä¸ªå…³ç³»
- âœ… **å®Œç¾è§£å†³ä½ çš„æ¡ˆä¾‹**: "å‰å¸ƒæ–¯ä¼ªå½±â†’æˆªæ–­ä¼ªå½±"æœ‰æ˜¾å¼è¾¹

**ç¼ºç‚¹**:
- âŒ ä»…é€‚ç”¨äºå›¾ä¸­å·²æœ‰å…³ç³»çš„å®ä½“å¯¹
- âŒ éœ€è¦å®šä¹‰å“ªäº›å…³ç³»ç±»å‹è¡¨ç¤ºåˆ«å

**å®æ–½æˆæœ¬**: â­ **1å¤©**

**é¢„æœŸæ•ˆæœ**:
- å¬å›ç‡æå‡: +15-25% (å–å†³äºå›¾ä¸­åˆ«åå…³ç³»æ•°é‡)
- ç²¾ç¡®ç‡: >95% (å…³ç³»æ ‡æ³¨é€šå¸¸å¾ˆå‡†ç¡®)

---

#### æ–¹æ¡ˆ2: å¤šç‰¹å¾èåˆ â­â­â­â­ **æ¨è**

**æ ¸å¿ƒé€»è¾‘**:
```python
score = (
    name_similarity * 0.3 +
    neighbor_similarity * 0.3 +
    relation_signature_similarity * 0.4
)
if score > 0.75:
    candidate_pairs.append((A, B, score, 'multi_feature'))
```

**ä¼˜ç‚¹**:
- âœ… **é²æ£’**: åç§°ä¸ç›¸ä¼¼æ—¶ï¼Œå…¶ä»–ç‰¹å¾å¯ä»¥è¡¥å¿
- âœ… **å…¨é¢**: ç»¼åˆå¤šç»´åº¦ä¿¡æ¯
- âœ… **å¯è°ƒ**: æƒé‡å¯æ ¹æ®é¢†åŸŸè°ƒæ•´

**ç¼ºç‚¹**:
- âŒ è®¡ç®—æˆæœ¬è¾ƒé«˜ (éœ€è¦è®¡ç®—é‚»å±…ã€å…³ç³»æ¨¡å¼ç­‰)
- âŒ éœ€è¦è°ƒå‚ç¡®å®šåˆé€‚æƒé‡
- âŒ ç‰¹å¾å·¥ç¨‹éœ€è¦ç»éªŒ

**å®æ–½æˆæœ¬**: â­â­ **1å‘¨**

**é¢„æœŸæ•ˆæœ**:
- å¬å›ç‡æå‡: +20-30%
- ç²¾ç¡®ç‡: 80-88% (å¯èƒ½æœ‰è¯¯åŒ¹é…)

---

#### æ–¹æ¡ˆ3: å­å›¾æè¿°ç›¸ä¼¼åº¦ â­â­ **ä¸å¤ªæ¨è**

**æ ¸å¿ƒé€»è¾‘**:
```python
desc_A = subgraph_to_text(extract_subgraph(A))
desc_B = subgraph_to_text(extract_subgraph(B))
similarity = cosine_sim(embed(desc_A), embed(desc_B))
```

**ä¼˜ç‚¹**:
- âœ… ä¸ä¾èµ–åç§°
- âœ… åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯

**ç¼ºç‚¹**:
- âŒ **ä½ æŒ‡å‡ºçš„å…³é”®é—®é¢˜**: å­å›¾å†…å®¹ä¸åŒæ—¶å¤±æ•ˆ
  - "å‰å¸ƒæ–¯ä¼ªå½±": å®šä¹‰ã€æœºåˆ¶
  - "æˆªæ–­ä¼ªå½±": è§£å†³æ–¹æ¡ˆ
  - â†’ æè¿°ç›¸ä¼¼åº¦ä»ç„¶ä½ï¼
- âŒ è®¡ç®—æˆæœ¬é«˜ï¼ˆæ¯å¯¹éƒ½è¦æå–å’Œç¼–ç å­å›¾ï¼‰
- âŒ å­å›¾å¤§å°éš¾ä»¥æ§åˆ¶

**å®æ–½æˆæœ¬**: â­â­â­ **1-2å‘¨**

**é¢„æœŸæ•ˆæœ**:
- å¬å›ç‡æå‡: +10-15% (æœ‰é™)
- ç²¾ç¡®ç‡: 75-82%
- **ä¸èƒ½è§£å†³ä½ çš„æ ¸å¿ƒæ¡ˆä¾‹**

**ç»“è®º**: âš ï¸ **ä¸ä½œä¸ºä¸»è¦æ–¹æ¡ˆï¼Œå¯ä½œä¸ºå¤šç‰¹å¾èåˆçš„ä¸€ä¸ªç‰¹å¾**

---

#### æ–¹æ¡ˆ4: æœºå™¨å­¦ä¹  â­â­â­â­ **é•¿æœŸæ–¹æ¡ˆ**

**æ ¸å¿ƒé€»è¾‘**:
```python
# ç”¨ç°æœ‰åˆ«åå…³ç³»ä½œä¸ºè®­ç»ƒæ•°æ®
model = train_classifier(positive=explicit_aliases, negative=random_pairs)
predictions = model.predict_proba(all_candidate_pairs)
```

**ä¼˜ç‚¹**:
- âœ… è‡ªåŠ¨å­¦ä¹ æ¨¡å¼ï¼Œæ— éœ€äººå·¥è§„åˆ™
- âœ… å¯ä»¥æ³›åŒ–åˆ°æœªè§è¿‡çš„æƒ…å†µ
- âœ… å¯ä»¥å¤„ç†å¤æ‚çš„éçº¿æ€§å…³ç³»

**ç¼ºç‚¹**:
- âŒ éœ€è¦è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®ï¼ˆ>100å¯¹ï¼‰
- âŒ éœ€è¦ç‰¹å¾å·¥ç¨‹
- âŒ æ¨¡å‹ç»´æŠ¤æˆæœ¬
- âŒ å¯è§£é‡Šæ€§è¾ƒå·®

**å®æ–½æˆæœ¬**: â­â­â­â­ **2-4å‘¨**

**é¢„æœŸæ•ˆæœ**:
- å¬å›ç‡æå‡: +25-35%
- ç²¾ç¡®ç‡: 85-92% (å–å†³äºè®­ç»ƒæ•°æ®è´¨é‡)

---

## ğŸ† æ¨èå®æ–½è·¯çº¿

### é˜¶æ®µ1: å¿«é€Ÿæ”¹è¿› (1å‘¨å†…) â­â­â­â­â­

**ç›®æ ‡**: ç«‹å³è§£å†³"å‰å¸ƒæ–¯ä¼ªå½±/æˆªæ–­ä¼ªå½±"ç±»é—®é¢˜

**å®æ–½æ–¹æ¡ˆ1: å…³ç³»æ„ŸçŸ¥å€™é€‰ç”Ÿæˆ**

```python
# æ–‡ä»¶: models/constructor/kt_gen.py
# ä½ç½®: _generate_semantic_candidates() ä¹‹å‰

def _generate_candidates_with_relations(
    self,
    remaining_nodes: List[str],
    max_candidates: int = 1000,
    similarity_threshold: float = 0.75
) -> List[Tuple[str, str, float, str]]:
    """
    æ”¹è¿›çš„å€™é€‰ç”Ÿæˆï¼šå…³ç³»ä¼˜å…ˆ + è¯­ä¹‰ç›¸ä¼¼åº¦
    
    Returns:
        List of (node_a, node_b, score, source)
    """
    candidates = []
    node_set = set(remaining_nodes)
    
    # ========================================
    # æ–°å¢éƒ¨åˆ†ï¼šä»æ˜¾å¼å…³ç³»ä¸­æå–å€™é€‰
    # ========================================
    alias_relations = self._get_alias_relation_types()
    
    for u, v, data in self.graph.edges(data=True):
        relation = data.get('relation', '')
        
        # åªè€ƒè™‘åœ¨remaining_nodesä¸­çš„èŠ‚ç‚¹
        if u not in node_set or v not in node_set:
            continue
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ«åå…³ç³»
        if relation in alias_relations:
            candidates.append((u, v, 0.95, 'explicit_alias'))
            logger.debug(f"Found explicit alias: {u} --[{relation}]--> {v}")
    
    logger.info(f"Found {len(candidates)} explicit alias pairs from relations")
    
    # ========================================
    # åŸæœ‰éƒ¨åˆ†ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦
    # ========================================
    semantic_candidates = self._generate_semantic_candidates(
        remaining_nodes,
        max_candidates=max_candidates - len(candidates),  # å‡å»å·²æœ‰çš„
        similarity_threshold=similarity_threshold
    )
    
    candidates.extend(semantic_candidates)
    
    # å»é‡ï¼šåŒä¸€å¯¹èŠ‚ç‚¹åªä¿ç•™æœ€é«˜åˆ†
    candidates = self._deduplicate_candidate_pairs(candidates)
    
    return candidates

def _get_alias_relation_types(self) -> Set[str]:
    """
    è·å–è¡¨ç¤ºåˆ«åçš„å…³ç³»ç±»å‹
    å¯ä»¥ä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
    """
    config = self.config.construction.semantic_dedup.head_dedup
    
    # ä»é…ç½®è¯»å–ï¼ˆå¦‚æœæœ‰ï¼‰
    if hasattr(config, 'alias_relation_types'):
        return set(config.alias_relation_types)
    
    # é»˜è®¤å€¼
    return {
        "åˆ«ååŒ…æ‹¬",
        "alias_of",
        "also_known_as",
        "åˆç§°",
        "synonym",
        "ä¹Ÿå«",
        "ç®€ç§°",
        "å…¨ç§°",
        "also_called"
    }

def _deduplicate_candidate_pairs(
    self,
    candidates: List[Tuple[str, str, float, str]]
) -> List[Tuple[str, str, float, str]]:
    """
    å»é‡å€™é€‰å¯¹ï¼Œä¿ç•™åˆ†æ•°æœ€é«˜çš„
    """
    pair_dict = {}
    
    for u, v, score, source in candidates:
        # æ ‡å‡†åŒ–é¡ºåºï¼ˆu < vï¼‰
        key = tuple(sorted([u, v]))
        
        if key not in pair_dict or score > pair_dict[key][2]:
            pair_dict[key] = (u, v, score, source)
    
    return list(pair_dict.values())
```

**é…ç½®æ–‡ä»¶ä¿®æ”¹**:

```yaml
# config/base_config.yaml
construction:
  semantic_dedup:
    head_dedup:
      enabled: true
      enable_semantic: true
      
      # æ–°å¢ï¼šåˆ«åå…³ç³»ç±»å‹å®šä¹‰
      alias_relation_types:
        - "åˆ«ååŒ…æ‹¬"
        - "alias_of"
        - "also_known_as"
        - "åˆç§°"
        - "synonym"
        - "ä¹Ÿå«"
        - "ç®€ç§°"
        - "å…¨ç§°"
      
      # æ–°å¢ï¼šå…³ç³»ä¼ æ’­è®¾ç½®
      enable_relation_propagation: true  # æ˜¯å¦å¯ç”¨ä¼ é€’é—­åŒ…
      propagation_max_hops: 2           # æœ€å¤šä¼ æ’­å‡ è·³
      
      similarity_threshold: 0.85
      candidate_similarity_threshold: 0.75
      # ... å…¶ä»–é…ç½®ä¿æŒä¸å˜
```

**é›†æˆåˆ°ä¸»æµç¨‹**:

```python
# æ–‡ä»¶: models/constructor/kt_gen.py
# æ–¹æ³•: deduplicate_heads()
# ä¿®æ”¹ä½ç½®: line ~4617

# === åŸæœ‰ä»£ç  ===
# candidate_pairs = self._generate_semantic_candidates(
#     remaining_nodes,
#     max_candidates=max_candidates,
#     similarity_threshold=candidate_similarity_threshold
# )

# === æ–°ä»£ç  ===
candidate_pairs = self._generate_candidates_with_relations(
    remaining_nodes,
    max_candidates=max_candidates,
    similarity_threshold=candidate_similarity_threshold
)
# å¢åŠ æ—¥å¿—
for u, v, score, source in candidate_pairs:
    if source == 'explicit_alias':
        logger.debug(f"  Alias pair: {u} â†” {v} (score={score:.3f}, source={source})")
```

**æµ‹è¯•éªŒè¯**:

```python
# åˆ›å»ºæµ‹è¯•æ–‡ä»¶: test_alias_relation_dedup.py

def test_explicit_alias_detection():
    """
    æµ‹è¯•æ˜¾å¼åˆ«åå…³ç³»çš„è¯†åˆ«
    """
    from models.constructor.kt_gen import KnowledgeTreeGen
    from config import get_config
    
    config = get_config()
    builder = KnowledgeTreeGen(dataset_name="test", config=config)
    
    # æ„é€ æµ‹è¯•å›¾
    builder.graph.add_node("entity_0", label="entity", 
                          properties={"name": "å‰å¸ƒæ–¯ä¼ªå½±"})
    builder.graph.add_node("entity_1", label="entity", 
                          properties={"name": "æˆªæ–­ä¼ªå½±"})
    builder.graph.add_node("entity_2", label="entity", 
                          properties={"name": "MRIä¼ªå½±"})
    
    # æ·»åŠ åˆ«åå…³ç³»
    builder.graph.add_edge("entity_0", "entity_1", 
                          relation="åˆ«ååŒ…æ‹¬",
                          source_chunks=["chunk_1"])
    
    # æ·»åŠ å…¶ä»–å…³ç³»
    builder.graph.add_edge("entity_0", "entity_2", 
                          relation="æ˜¯ä¸€ç§",
                          source_chunks=["chunk_2"])
    
    # æµ‹è¯•å€™é€‰ç”Ÿæˆ
    candidates = builder._generate_candidates_with_relations(
        remaining_nodes=["entity_0", "entity_1", "entity_2"],
        max_candidates=100,
        similarity_threshold=0.75
    )
    
    # éªŒè¯
    alias_candidates = [c for c in candidates if c[3] == 'explicit_alias']
    assert len(alias_candidates) >= 1, "Should find at least 1 explicit alias pair"
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æˆ‘ä»¬çš„æµ‹è¯•å¯¹
    found = False
    for u, v, score, source in alias_candidates:
        if {u, v} == {"entity_0", "entity_1"}:
            found = True
            assert score >= 0.9, "Explicit alias should have high score"
            break
    
    assert found, "Should find the explicit alias pair: å‰å¸ƒæ–¯ä¼ªå½± â†” æˆªæ–­ä¼ªå½±"
    
    print("âœ“ Test passed: Explicit alias detection works!")

if __name__ == "__main__":
    test_explicit_alias_detection()
```

**é¢„æœŸæ•ˆæœ**:

| æŒ‡æ ‡ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡ |
|-----|-------|-------|-----|
| è¯†åˆ«åˆ«åå¯¹æ•° | 100 | 125-140 | +25-40% |
| ä½è¯­ä¹‰ç›¸ä¼¼åº¦åˆ«åå¬å› | 0% | 90-95% | +90% |
| ç²¾ç¡®ç‡ | 92% | 93-95% | +1-3% |
| è®¡ç®—æ—¶é—´å¢åŠ  | - | <5% | å¯å¿½ç•¥ |

---

### é˜¶æ®µ2: å¢å¼ºé²æ£’æ€§ (1ä¸ªæœˆå†…) â­â­â­â­

**ç›®æ ‡**: å¤„ç†æ²¡æœ‰æ˜¾å¼å…³ç³»ä½†åº”è¯¥åˆå¹¶çš„å®ä½“

**å®æ–½æ–¹æ¡ˆ2: å¤šç‰¹å¾èåˆ**

```python
# æ–°å¢æ–¹æ³•: _compute_multi_feature_similarity()

def _compute_multi_feature_similarity(
    self,
    node_a: str,
    node_b: str
) -> Tuple[float, Dict[str, float]]:
    """
    è®¡ç®—å¤šç‰¹å¾èåˆåçš„ç›¸ä¼¼åº¦åˆ†æ•°
    
    Returns:
        (combined_score, feature_details)
    """
    features = {}
    
    # Feature 1: åç§°ç›¸ä¼¼åº¦ (åŸºç¡€)
    name_sim = self._compute_name_similarity(node_a, node_b)
    features['name_similarity'] = name_sim
    
    # Feature 2: æ˜¾å¼å…³ç³»æ£€æŸ¥
    has_alias_rel = self._check_alias_relation(node_a, node_b)
    features['has_alias_relation'] = 1.0 if has_alias_rel else 0.0
    
    # Feature 3: é‚»å±…ç›¸ä¼¼åº¦
    neighbor_sim = self._compute_neighbor_similarity(node_a, node_b)
    features['neighbor_similarity'] = neighbor_sim
    
    # Feature 4: å…³ç³»ç±»å‹ç­¾åç›¸ä¼¼åº¦
    relation_sig_sim = self._compute_relation_signature_similarity(node_a, node_b)
    features['relation_signature_similarity'] = relation_sig_sim
    
    # Feature 5: å…±åŒè·¯å¾„
    common_paths = self._count_common_paths(node_a, node_b, max_length=3)
    features['common_paths'] = min(1.0, common_paths / 5.0)  # å½’ä¸€åŒ–
    
    # åˆ†å±‚å†³ç­–
    if features['has_alias_relation'] > 0:
        # æœ‰æ˜¾å¼å…³ç³» â†’ é«˜åˆ†
        combined_score = 0.95
    elif name_sim > 0.85:
        # åç§°é«˜åº¦ç›¸ä¼¼ â†’ ä¸­é«˜åˆ†
        combined_score = name_sim
    elif name_sim > 0.60:
        # åç§°ä¸­åº¦ç›¸ä¼¼ â†’ éœ€è¦å…¶ä»–ç‰¹å¾æ”¯æŒ
        combined_score = (
            name_sim * 0.4 +
            neighbor_sim * 0.3 +
            relation_sig_sim * 0.3
        )
    elif neighbor_sim > 0.80 or relation_sig_sim > 0.80:
        # åç§°ä½ç›¸ä¼¼ä½†å…¶ä»–ç‰¹å¾å¼º â†’ ä¸­åˆ†
        combined_score = (
            name_sim * 0.2 +
            neighbor_sim * 0.4 +
            relation_sig_sim * 0.4
        )
    else:
        # éƒ½ä¸å¼º â†’ ä½åˆ†
        combined_score = name_sim * 0.5 + max(neighbor_sim, relation_sig_sim) * 0.5
    
    return combined_score, features

def _compute_neighbor_similarity(self, node_a: str, node_b: str) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹çš„é‚»å±…ç›¸ä¼¼åº¦ï¼ˆJaccardï¼‰
    """
    neighbors_a = set(self.graph.neighbors(node_a))
    neighbors_b = set(self.graph.neighbors(node_b))
    
    if not neighbors_a and not neighbors_b:
        return 0.0
    
    intersection = len(neighbors_a & neighbors_b)
    union = len(neighbors_a | neighbors_b)
    
    return intersection / union if union > 0 else 0.0

def _compute_relation_signature_similarity(self, node_a: str, node_b: str) -> float:
    """
    è®¡ç®—å…³ç³»æ¨¡å¼ç›¸ä¼¼åº¦ï¼ˆåªçœ‹å…³ç³»ç±»å‹ï¼Œä¸çœ‹ç›®æ ‡å®ä½“ï¼‰
    """
    # å‡ºè¾¹å…³ç³»ç±»å‹
    out_rels_a = [data['relation'] for _, _, data in self.graph.out_edges(node_a, data=True)]
    out_rels_b = [data['relation'] for _, _, data in self.graph.out_edges(node_b, data=True)]
    
    # å…¥è¾¹å…³ç³»ç±»å‹
    in_rels_a = [data['relation'] for _, _, data in self.graph.in_edges(node_a, data=True)]
    in_rels_b = [data['relation'] for _, _, data in self.graph.in_edges(node_b, data=True)]
    
    # Jaccardç›¸ä¼¼åº¦
    def jaccard_multiset(list1, list2):
        from collections import Counter
        c1, c2 = Counter(list1), Counter(list2)
        intersection = sum((c1 & c2).values())
        union = sum((c1 | c2).values())
        return intersection / union if union > 0 else 0.0
    
    out_sim = jaccard_multiset(out_rels_a, out_rels_b)
    in_sim = jaccard_multiset(in_rels_a, in_rels_b)
    
    return (out_sim + in_sim) / 2

def _count_common_paths(self, node_a: str, node_b: str, max_length: int = 3) -> int:
    """
    è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„å…±åŒè·¯å¾„æ•°é‡
    """
    try:
        # ç®€å•å®ç°ï¼šæ£€æŸ¥æ˜¯å¦åœ¨max_lengthè·³å†…å¯è¾¾
        import networkx as nx
        length = nx.shortest_path_length(self.graph, node_a, node_b)
        if length <= max_length:
            return max_length - length + 1
        return 0
    except (nx.NetworkXNoPath, nx.NodeNotFound):
        return 0
```

**é›†æˆæ–¹å¼**:

```python
# åœ¨éªŒè¯é˜¶æ®µä½¿ç”¨å¤šç‰¹å¾è¯„åˆ†
def _validate_candidates_with_embedding(
    self,
    candidate_pairs: List[Tuple[str, str, float]],
    threshold: float = 0.85
) -> Tuple[Dict[str, str], Dict[str, dict]]:
    """
    æ”¹è¿›ï¼šä½¿ç”¨å¤šç‰¹å¾è¯„åˆ†æ›¿ä»£å•ä¸€embeddingç›¸ä¼¼åº¦
    """
    merge_mapping = {}
    metadata = {}
    
    for node_a, node_b, initial_score in candidate_pairs:
        # ä½¿ç”¨å¤šç‰¹å¾èåˆ
        combined_score, feature_details = self._compute_multi_feature_similarity(
            node_a, node_b
        )
        
        if combined_score >= threshold:
            # é€‰æ‹©representative
            canonical, duplicate = self._select_canonical_node(node_a, node_b)
            merge_mapping[duplicate] = canonical
            
            metadata[duplicate] = {
                'method': 'multi_feature',
                'score': combined_score,
                'features': feature_details,
                'paired_with': canonical
            }
    
    return merge_mapping, metadata
```

---

### é˜¶æ®µ3: å…³ç³»ä¼ æ’­ (å¯é€‰) â­â­â­

**ç›®æ ‡**: è‡ªåŠ¨æ¨æ–­éšå«çš„åˆ«åå…³ç³»

```python
def _propagate_alias_relations(
    self,
    max_hops: int = 2
) -> List[Tuple[str, str, float]]:
    """
    åˆ«åå…³ç³»ä¼ æ’­
    
    è§„åˆ™:
    1. ä¼ é€’æ€§: Aâ†’Bâ†’C (éƒ½æ˜¯åˆ«å) => A, Cä¹Ÿæ˜¯åˆ«å
    2. å…±åŒåˆ«å: Aâ†’C, Bâ†’C (éƒ½æ˜¯åˆ«å) ä¸” name_sim(A,B) > 0.6 => A, Bå¯èƒ½æ˜¯åˆ«å
    """
    propagated_pairs = []
    alias_relations = self._get_alias_relation_types()
    
    # æ„å»ºåˆ«åå›¾
    alias_graph = nx.DiGraph()
    for u, v, data in self.graph.edges(data=True):
        if data.get('relation') in alias_relations:
            alias_graph.add_edge(u, v)
    
    # è§„åˆ™1: ä¼ é€’é—­åŒ…
    for component in nx.weakly_connected_components(alias_graph):
        component_list = list(component)
        for i in range(len(component_list)):
            for j in range(i+1, len(component_list)):
                u, v = component_list[i], component_list[j]
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›´æ¥è¾¹
                if not alias_graph.has_edge(u, v) and not alias_graph.has_edge(v, u):
                    propagated_pairs.append((u, v, 0.90, 'transitive'))
    
    # è§„åˆ™2: å…±åŒåˆ«åæ¨æ–­
    # (ç•¥ï¼Œè§ALIAS_ENTITY_DEDUP_RESEARCH.mdä¸­çš„è¯¦ç»†å®ç°)
    
    return propagated_pairs
```

---

## ğŸ“Š æ•ˆæœé¢„æµ‹

### é‡åŒ–æŒ‡æ ‡

| é˜¶æ®µ | æ”¹è¿›å†…å®¹ | å¬å›ç‡æå‡ | ç²¾ç¡®ç‡å˜åŒ– | å®æ–½æ—¶é—´ |
|-----|---------|-----------|-----------|---------|
| **é˜¶æ®µ1** | æ˜¾å¼å…³ç³»ä¼˜å…ˆ | +15-25% | +1-3% | 1å‘¨ |
| **é˜¶æ®µ2** | å¤šç‰¹å¾èåˆ | +20-30% | -2-0% | 1ä¸ªæœˆ |
| **é˜¶æ®µ3** | å…³ç³»ä¼ æ’­ | +5-10% | -1-0% | 1å‘¨ |
| **æ€»è®¡** | å…¨éƒ¨å®æ–½ | +40-65% | +0-2% | 2ä¸ªæœˆ |

### å…¸å‹æ¡ˆä¾‹æ•ˆæœ

**æ¡ˆä¾‹1: å‰å¸ƒæ–¯ä¼ªå½±/æˆªæ–­ä¼ªå½±**
- æ”¹è¿›å‰: âŒ ä¸è¯†åˆ« (åç§°ç›¸ä¼¼åº¦0.65 < 0.75)
- æ”¹è¿›å: âœ… è¯†åˆ« (æ˜¾å¼å…³ç³» "åˆ«ååŒ…æ‹¬", åˆ†æ•°0.95)

**æ¡ˆä¾‹2: CPU/ä¸­å¤®å¤„ç†å™¨**
- æ”¹è¿›å‰: âŒ ä¸è¯†åˆ« (åç§°ç›¸ä¼¼åº¦0.55)
- æ”¹è¿›å: âœ… è¯†åˆ« (é‚»å±…ç›¸ä¼¼åº¦0.85 + å…³ç³»ç­¾å0.90 â†’ ç»¼åˆ0.82)

**æ¡ˆä¾‹3: åŒ—äº¬/Beijing**
- æ”¹è¿›å‰: âœ… è¯†åˆ« (åç§°ç›¸ä¼¼åº¦0.75)
- æ”¹è¿›å: âœ… è¯†åˆ« (åç§°ç›¸ä¼¼åº¦0.75ï¼Œæˆ–æ˜¾å¼å…³ç³»)

---

## ğŸ§ª æµ‹è¯•è®¡åˆ’

### å•å…ƒæµ‹è¯•

```python
# test_alias_dedup_improvements.py

def test_explicit_alias_extraction():
    """æµ‹è¯•æ˜¾å¼åˆ«åå…³ç³»æå–"""
    # è§ä¸Šæ–‡

def test_multi_feature_scoring():
    """æµ‹è¯•å¤šç‰¹å¾è¯„åˆ†"""
    builder = setup_test_graph()
    
    # æµ‹è¯•1: åç§°ä½ä½†é‚»å±…é«˜
    score, features = builder._compute_multi_feature_similarity(
        "node_with_low_name_sim_high_neighbor",
        "node_target"
    )
    assert score > 0.70, "Should score high with high neighbor similarity"
    
    # æµ‹è¯•2: æœ‰æ˜¾å¼å…³ç³»
    score, features = builder._compute_multi_feature_similarity(
        "node_with_alias_relation",
        "node_target"
    )
    assert score >= 0.90, "Explicit relation should give high score"

def test_relation_propagation():
    """æµ‹è¯•å…³ç³»ä¼ æ’­"""
    builder = setup_test_graph()
    # Aâ†’B, Bâ†’C (éƒ½æ˜¯åˆ«å)
    propagated = builder._propagate_alias_relations()
    # åº”è¯¥æ¨æ–­å‡º A, Cä¹Ÿæ˜¯åˆ«å
    assert ("A", "C") in [(p[0], p[1]) for p in propagated]
```

### é›†æˆæµ‹è¯•

```python
def test_end_to_end_dedup():
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    config = get_config()
    builder = KnowledgeTreeGen(dataset_name="medical_test", config=config)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    builder.build_knowledge_graph("data/medical_test_corpus.json")
    
    # æ‰§è¡Œå»é‡
    stats_before = builder.get_graph_stats()
    dedup_stats = builder.deduplicate_heads()
    stats_after = builder.get_graph_stats()
    
    # éªŒè¯
    assert dedup_stats['total_merges'] > 0
    assert stats_after['num_nodes'] < stats_before['num_nodes']
    
    # æ£€æŸ¥ç‰¹å®šæ¡ˆä¾‹
    assert not builder.graph.has_node("æˆªæ–­ä¼ªå½±")  # åº”è¯¥è¢«åˆå¹¶
    assert builder.graph.has_node("å‰å¸ƒæ–¯ä¼ªå½±")    # ä¿ç•™
```

---

## ğŸ“ æ€»ç»“ä¸å»ºè®®

### æ ¸å¿ƒè§‚ç‚¹

1. **ä½ çš„è§‚å¯Ÿå®Œå…¨æ­£ç¡®**: ä»…ä¾èµ–åç§°è¯­ä¹‰ç›¸ä¼¼åº¦ç¡®å®ä¸å¤Ÿ
2. **æ–¹æ¡ˆ2ï¼ˆæ˜¾å¼å…³ç³»ï¼‰ä¼˜äºæ–¹æ¡ˆ1ï¼ˆå­å›¾æè¿°ï¼‰**: 
   - æ›´å‡†ç¡®
   - æ›´é«˜æ•ˆ
   - å¯è§£é‡Šæ€§æ›´å¼º
3. **"ä¸æ˜¯åŸºäºç›¸ä¼¼åº¦ï¼Œè€Œæ˜¯åŸºäºé€»è¾‘å…³ç³»" - è¿™æ­£æ˜¯æ­£ç¡®çš„æ–¹å‘ï¼**

### å®æ–½å»ºè®®

**çŸ­æœŸï¼ˆç«‹å³å¼€å§‹ï¼‰**:
1. âœ… å®æ–½é˜¶æ®µ1ï¼šæ˜¾å¼å…³ç³»ä¼˜å…ˆ
   - ä¿®æ”¹å€™é€‰ç”Ÿæˆå‡½æ•°
   - æ·»åŠ é…ç½®é€‰é¡¹
   - ç¼–å†™å•å…ƒæµ‹è¯•

**ä¸­æœŸï¼ˆ1ä¸ªæœˆå†…ï¼‰**:
2. âœ… å®æ–½é˜¶æ®µ2ï¼šå¤šç‰¹å¾èåˆ
   - æ·»åŠ é‚»å±…ã€å…³ç³»ç­¾åç­‰ç‰¹å¾
   - å®ç°åˆ†å±‚å†³ç­–é€»è¾‘
   - è¿›è¡Œæ•ˆæœå¯¹æ¯”

**é•¿æœŸï¼ˆ3ä¸ªæœˆåï¼‰**:
3. ğŸ”¬ è¯„ä¼°æ˜¯å¦éœ€è¦æœºå™¨å­¦ä¹ æ–¹æ³•
   - å–å†³äºæ•°æ®é‡å’Œæ•ˆæœéœ€æ±‚
   - å¦‚æœé˜¶æ®µ1+2å·²ç»æ»¡è¶³éœ€æ±‚ï¼Œå¯ä»¥ä¸åš

### é£é™©æç¤º

âš ï¸ **æ³¨æ„äº‹é¡¹**:
1. **å…³ç³»è´¨é‡**: æ˜¾å¼å…³ç³»æ–¹æ³•ä¾èµ–äºåŸå§‹å…³ç³»æ ‡æ³¨çš„è´¨é‡
2. **å…³ç³»ç±»å‹å®šä¹‰**: éœ€è¦ä»”ç»†å®šä¹‰å“ªäº›å…³ç³»è¡¨ç¤ºåˆ«å
3. **ä¼ é€’æ€§é£é™©**: Aâ†’B, Bâ†’Cä¸ä¸€å®šæ„å‘³ç€Aâ†’Cï¼ˆéœ€è¦éªŒè¯ï¼‰
4. **æ€§èƒ½å¼€é”€**: å¤šç‰¹å¾è®¡ç®—ä¼šå¢åŠ æ—¶é—´ï¼Œéœ€è¦ç›‘æ§

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… å®ç°é˜¶æ®µ1ä»£ç ï¼ˆè§ä¸Šæ–‡è¯¦ç»†ä»£ç ï¼‰
2. âœ… åœ¨å°æ•°æ®é›†ä¸Šæµ‹è¯•æ•ˆæœ
3. âœ… æ ¹æ®åé¦ˆè°ƒæ•´é…ç½®å’Œæƒé‡
4. âœ… éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
5. ğŸ“Š æ”¶é›†æ•ˆæœæ•°æ®ï¼Œå†³å®šæ˜¯å¦è¿›å…¥é˜¶æ®µ2

---

**å¸Œæœ›è¿™ä¸ªå®æ–½æ–¹æ¡ˆå¯¹ä½ æœ‰å¸®åŠ©ï¼å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œéšæ—¶æ²Ÿé€šã€‚** ğŸ‰
