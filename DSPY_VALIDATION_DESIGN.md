# DSPy Validation è®¾è®¡ - Semantic Dedupè´¨é‡æ ¡éªŒ

## ğŸ¯ é—®é¢˜

åœ¨semantic dedupä¹‹åï¼Œå¦‚ä½•ä½¿ç”¨DSPyè¿›è¡Œè´¨é‡æ ¡éªŒï¼Ÿ

## âœ… ç­”æ¡ˆ

**å®Œå…¨æ”¯æŒï¼** DSPyéå¸¸é€‚åˆæ„å»ºå¤šé˜¶æ®µpipelineï¼ŒåŒ…æ‹¬ï¼š
1. **å»é‡é˜¶æ®µ** (Deduplication)
2. **æ ¡éªŒé˜¶æ®µ** (Validation/Verification)
3. **ä¿®æ­£é˜¶æ®µ** (Correctionï¼Œå¯é€‰)

---

## ğŸ—ï¸ å¤šé˜¶æ®µæ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     DSPy Multi-Stage Semantic Dedup Pipeline        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  Stage 1: Clustering                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ SemanticClusteringModule     â”‚                  â”‚
â”‚  â”‚ Input: tails                 â”‚                  â”‚
â”‚  â”‚ Output: clusters             â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                    â†“                                â”‚
â”‚  Stage 2: Deduplication                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ SemanticDedupModule          â”‚                  â”‚
â”‚  â”‚ Input: clusters + contexts   â”‚                  â”‚
â”‚  â”‚ Output: groups (merged)      â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                    â†“                                â”‚
â”‚  Stage 3: Validation â­ NEW                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ DedupValidationModule        â”‚                  â”‚
â”‚  â”‚ Input: original + groups     â”‚                  â”‚
â”‚  â”‚ Output: validation results   â”‚                  â”‚
â”‚  â”‚   - Quality score            â”‚                  â”‚
â”‚  â”‚   - Potential errors         â”‚                  â”‚
â”‚  â”‚   - Suggestions              â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                    â†“                                â”‚
â”‚  Stage 4: Correction (Optional)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ DedupCorrectionModule        â”‚                  â”‚
â”‚  â”‚ Input: groups + validation   â”‚                  â”‚
â”‚  â”‚ Output: corrected groups     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ éªŒè¯ç±»å‹

### 1. è´¨é‡è¯„åˆ† (Quality Scoring)
- è¯„ä¼°æ¯ä¸ªmergeçš„ç½®ä¿¡åº¦
- æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾é”™è¯¯
- ç»™å‡ºæ•´ä½“è´¨é‡åˆ†æ•°

### 2. é”™è¯¯æ£€æµ‹ (Error Detection)
- **False Positive**: ä¸åº”è¯¥åˆå¹¶ä½†è¢«åˆå¹¶äº†
  - ä¾‹å¦‚ï¼šiPhone 13 å’Œ iPhone 14 è¢«é”™è¯¯åˆå¹¶
- **False Negative**: åº”è¯¥åˆå¹¶ä½†è¢«åˆ†å¼€äº†
  - ä¾‹å¦‚ï¼šNYC å’Œ New York City è¢«åˆ†åœ¨ä¸åŒç»„
- **Representativeé”™è¯¯**: é€‰æ‹©çš„representativeä¸æ˜¯æœ€å¥½çš„

### 3. ä¸€è‡´æ€§æ£€æŸ¥ (Consistency Check)
- åŒä¸€ä¸ªentityåœ¨ä¸åŒrelationä¸­çš„å¤„ç†æ˜¯å¦ä¸€è‡´
- åˆå¹¶é€»è¾‘æ˜¯å¦ç¬¦åˆé¢„å®šä¹‰è§„åˆ™
- Contextè¯æ®æ˜¯å¦æ”¯æŒåˆå¹¶å†³ç­–

---

## ğŸ’» DSPy Signatureå®šä¹‰

### Validation Signature

```python
class DedupValidation(dspy.Signature):
    """
    éªŒè¯semantic dedupçš„è´¨é‡ã€‚
    
    æ£€æŸ¥åˆå¹¶å†³ç­–æ˜¯å¦æ­£ç¡®ï¼Œè¯†åˆ«æ½œåœ¨é”™è¯¯ï¼Œå¹¶ç»™å‡ºè´¨é‡è¯„åˆ†ã€‚
    """
    
    head_entity: str = dspy.InputField(
        desc="The head entity"
    )
    relation: str = dspy.InputField(
        desc="The relation type"
    )
    original_tails: str = dspy.InputField(
        desc="Original list of tails before dedup. Format: [1] tail1\\n[2] tail2\\n..."
    )
    dedup_groups: str = dspy.InputField(
        desc=(
            "Deduplication results. JSON format: "
            "[{\"members\": [1,2], \"representative\": 1, \"rationale\": \"...\"}]"
        )
    )
    contexts: str = dspy.InputField(
        desc="Context information for each tail"
    )
    
    analysis: str = dspy.OutputField(
        desc=(
            "Detailed validation analysis:\\n"
            "1. Check each group for correctness\\n"
            "2. Identify potential false positives (wrong merges)\\n"
            "3. Identify potential false negatives (missed merges)\\n"
            "4. Evaluate representative selection\\n"
            "5. Assess evidence quality from contexts"
        )
    )
    
    validation_results: str = dspy.OutputField(
        desc=(
            "JSON validation results:\\n"
            "{\\n"
            "  \"overall_quality\": 0.0-1.0,\\n"
            "  \"issues\": [\\n"
            "    {\\n"
            "      \"type\": \"false_positive|false_negative|bad_representative\",\\n"
            "      \"severity\": \"high|medium|low\",\\n"
            "      \"group_id\": int,\\n"
            "      \"description\": \"...\",\\n"
            "      \"suggestion\": \"...\"\\n"
            "    }\\n"
            "  ],\\n"
            "  \"group_scores\": [{\"group_id\": 0, \"confidence\": 0.95}, ...]\\n"
            "}"
        )
    )


class DedupCorrection(dspy.Signature):
    """
    åŸºäºvalidationç»“æœä¿®æ­£dedupå†³ç­–ã€‚
    """
    
    head_entity: str = dspy.InputField(desc="The head entity")
    relation: str = dspy.InputField(desc="The relation")
    original_tails: str = dspy.InputField(desc="Original tails")
    current_groups: str = dspy.InputField(desc="Current dedup groups (possibly incorrect)")
    validation_issues: str = dspy.InputField(desc="Issues identified by validation")
    contexts: str = dspy.InputField(desc="Context information")
    
    reasoning: str = dspy.OutputField(
        desc="Step-by-step reasoning for corrections"
    )
    
    corrected_groups: str = dspy.OutputField(
        desc="Corrected deduplication groups in JSON format"
    )
```

---

## ğŸ”§ Moduleå®ç°

```python
import dspy
from typing import List, Dict, Tuple
import json
import json_repair


class DedupValidationModule(dspy.Module):
    """
    DSPyæ¨¡å—: éªŒè¯semantic dedupçš„è´¨é‡
    
    è¿™ä¸ªæ¨¡å—æ£€æŸ¥dedupç»“æœï¼Œè¯†åˆ«æ½œåœ¨é”™è¯¯ï¼Œå¹¶ç»™å‡ºè´¨é‡è¯„åˆ†ã€‚
    """
    
    def __init__(self, use_cot: bool = True):
        super().__init__()
        
        if use_cot:
            self.validate = dspy.ChainOfThought(DedupValidation)
        else:
            self.validate = dspy.Predict(DedupValidation)
    
    def forward(
        self,
        head_entity: str,
        relation: str,
        original_tails: List[str],
        dedup_groups: List[Dict],
        contexts: List[List[str]] = None
    ) -> Dict:
        """
        éªŒè¯å»é‡ç»“æœ
        
        Args:
            head_entity: å¤´å®ä½“
            relation: å…³ç³»
            original_tails: åŸå§‹çš„tailåˆ—è¡¨
            dedup_groups: å»é‡åçš„åˆ†ç»„
            contexts: æ¯ä¸ªtailçš„ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        # Format inputs
        tails_text = "\n".join([f"[{i+1}] {tail}" for i, tail in enumerate(original_tails)])
        groups_json = json.dumps(dedup_groups, ensure_ascii=False)
        
        # Format contexts
        if contexts:
            contexts_blocks = []
            for i, tail_contexts in enumerate(contexts, 1):
                context_str = "\n    ".join(tail_contexts) if tail_contexts else "- (no context)"
                contexts_blocks.append(f"[{i}] Contexts:\n    {context_str}")
            contexts_text = "\n".join(contexts_blocks)
        else:
            contexts_text = "- (no context available)"
        
        try:
            # Call validation
            result = self.validate(
                head_entity=head_entity,
                relation=relation,
                original_tails=tails_text,
                dedup_groups=groups_json,
                contexts=contexts_text
            )
            
            # Parse validation results
            validation_results = json_repair.loads(result.validation_results)
            
            return {
                "analysis": result.analysis,
                "overall_quality": validation_results.get("overall_quality", 0.0),
                "issues": validation_results.get("issues", []),
                "group_scores": validation_results.get("group_scores", []),
                "raw_results": validation_results
            }
        
        except Exception as e:
            print(f"Validation failed: {e}")
            # Return default (assume OK)
            return {
                "analysis": f"Validation failed: {e}",
                "overall_quality": 0.5,
                "issues": [],
                "group_scores": [],
                "raw_results": {}
            }


class DedupCorrectionModule(dspy.Module):
    """
    DSPyæ¨¡å—: åŸºäºvalidationç»“æœä¿®æ­£å»é‡å†³ç­–
    """
    
    def __init__(self, use_cot: bool = True):
        super().__init__()
        
        if use_cot:
            self.correct = dspy.ChainOfThought(DedupCorrection)
        else:
            self.correct = dspy.Predict(DedupCorrection)
    
    def forward(
        self,
        head_entity: str,
        relation: str,
        original_tails: List[str],
        current_groups: List[Dict],
        validation_issues: List[Dict],
        contexts: List[List[str]] = None
    ) -> Tuple[List[Dict], str]:
        """
        ä¿®æ­£å»é‡ç»“æœ
        
        Args:
            head_entity: å¤´å®ä½“
            relation: å…³ç³»
            original_tails: åŸå§‹tails
            current_groups: å½“å‰çš„åˆ†ç»„ï¼ˆå¯èƒ½æœ‰é”™è¯¯ï¼‰
            validation_issues: å‘ç°çš„é—®é¢˜
            contexts: ä¸Šä¸‹æ–‡
        
        Returns:
            (corrected_groups, reasoning)
        """
        # Format inputs
        tails_text = "\n".join([f"[{i+1}] {tail}" for i, tail in enumerate(original_tails)])
        groups_json = json.dumps(current_groups, ensure_ascii=False)
        issues_json = json.dumps(validation_issues, ensure_ascii=False)
        
        if contexts:
            contexts_blocks = []
            for i, tail_contexts in enumerate(contexts, 1):
                context_str = "\n    ".join(tail_contexts) if tail_contexts else "- (no context)"
                contexts_blocks.append(f"[{i}]:\n    {context_str}")
            contexts_text = "\n".join(contexts_blocks)
        else:
            contexts_text = "- (no context)"
        
        try:
            result = self.correct(
                head_entity=head_entity,
                relation=relation,
                original_tails=tails_text,
                current_groups=groups_json,
                validation_issues=issues_json,
                contexts=contexts_text
            )
            
            corrected_groups = json_repair.loads(result.corrected_groups)
            reasoning = result.reasoning
            
            return corrected_groups, reasoning
        
        except Exception as e:
            print(f"Correction failed: {e}")
            # Return original groups
            return current_groups, f"Correction failed: {e}"


class MultiStageDedupPipeline(dspy.Module):
    """
    å®Œæ•´çš„å¤šé˜¶æ®µå»é‡pipeline: Clustering â†’ Dedup â†’ Validation â†’ Correction
    """
    
    def __init__(
        self,
        enable_validation: bool = True,
        enable_correction: bool = False,
        validation_threshold: float = 0.7
    ):
        """
        Args:
            enable_validation: æ˜¯å¦å¯ç”¨éªŒè¯
            enable_correction: æ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¿®æ­£ï¼ˆéœ€è¦enable_validation=Trueï¼‰
            validation_threshold: è´¨é‡é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è§¦å‘correction
        """
        super().__init__()
        
        from models.constructor.dspy_semantic_dedup import (
            SemanticClusteringModule,
            SemanticDedupModule
        )
        
        # Stage 1: Clustering
        self.clustering = SemanticClusteringModule(use_cot=True)
        
        # Stage 2: Dedup
        self.dedup = SemanticDedupModule(use_cot=True)
        
        # Stage 3: Validation
        self.enable_validation = enable_validation
        if enable_validation:
            self.validation = DedupValidationModule(use_cot=True)
        
        # Stage 4: Correction
        self.enable_correction = enable_correction
        self.validation_threshold = validation_threshold
        if enable_correction:
            self.correction = DedupCorrectionModule(use_cot=True)
    
    def forward(
        self,
        head_entity: str,
        relation: str,
        tail_descriptions: List[str],
        contexts: List[List[str]] = None
    ) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´çš„å¤šé˜¶æ®µå»é‡pipeline
        
        Returns:
            {
                "clusters": [...],
                "initial_groups": [...],
                "validation": {...},
                "final_groups": [...],
                "corrections_applied": bool,
                "reasoning": {...}
            }
        """
        result = {
            "clusters": [],
            "initial_groups": [],
            "validation": None,
            "final_groups": [],
            "corrections_applied": False,
            "reasoning": {}
        }
        
        # Stage 1: Clustering
        print("Stage 1: Clustering...")
        clusters = self.clustering(
            head_entity=head_entity,
            relation=relation,
            tail_descriptions=tail_descriptions
        )
        result["clusters"] = clusters
        
        # Stage 2: Dedup
        print("Stage 2: Deduplication...")
        batch_entries = [
            {
                "description": desc,
                "context_summaries": contexts[i] if contexts else ["- (no context)"]
            }
            for i, desc in enumerate(tail_descriptions)
        ]
        
        head_contexts = ["- Context for head entity"]
        groups, dedup_reasoning = self.dedup(
            head_entity=head_entity,
            relation=relation,
            head_contexts=head_contexts,
            batch_entries=batch_entries
        )
        result["initial_groups"] = groups
        result["reasoning"]["dedup"] = dedup_reasoning
        
        # Stage 3: Validation
        if self.enable_validation:
            print("Stage 3: Validation...")
            validation_result = self.validation(
                head_entity=head_entity,
                relation=relation,
                original_tails=tail_descriptions,
                dedup_groups=groups,
                contexts=contexts
            )
            result["validation"] = validation_result
            
            quality = validation_result.get("overall_quality", 1.0)
            issues = validation_result.get("issues", [])
            
            print(f"  Quality Score: {quality:.2f}")
            print(f"  Issues Found: {len(issues)}")
            
            # Stage 4: Correction (if needed)
            if self.enable_correction and quality < self.validation_threshold and issues:
                print(f"Stage 4: Correction (quality {quality:.2f} < threshold {self.validation_threshold})...")
                corrected_groups, correction_reasoning = self.correction(
                    head_entity=head_entity,
                    relation=relation,
                    original_tails=tail_descriptions,
                    current_groups=groups,
                    validation_issues=issues,
                    contexts=contexts
                )
                result["final_groups"] = corrected_groups
                result["corrections_applied"] = True
                result["reasoning"]["correction"] = correction_reasoning
                print("  âœ“ Corrections applied")
            else:
                result["final_groups"] = groups
                print("  âœ“ No corrections needed")
        else:
            result["final_groups"] = groups
        
        return result
```

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: åŸºæœ¬éªŒè¯

```python
import dspy
from models.constructor.dspy_semantic_dedup import SemanticDedupModule

# é…ç½®DSPy
dspy.settings.configure(lm=dspy.OpenAI(model="gpt-3.5-turbo", api_key="YOUR_KEY"))

# 1. å…ˆè¿›è¡Œå»é‡
dedup_module = SemanticDedupModule()

tails = [
    "iPhone 13",
    "iPhone 14",
    "iPhone thirteen",
    "iPhone 15"
]

batch_entries = [
    {"description": tail, "context_summaries": [f"- {tail} is a smartphone"]}
    for tail in tails
]

groups, reasoning = dedup_module(
    head_entity="Apple Inc.",
    relation="product",
    head_contexts=["- Apple Inc. is a technology company"],
    batch_entries=batch_entries
)

print("Dedup Results:")
for group in groups:
    print(f"  Group: {[tails[i-1] for i in group['members']]}")

# 2. éªŒè¯å»é‡ç»“æœ
validation_module = DedupValidationModule()

validation_result = validation_module(
    head_entity="Apple Inc.",
    relation="product",
    original_tails=tails,
    dedup_groups=groups,
    contexts=[[f"- {tail} is a smartphone"] for tail in tails]
)

print("\nValidation Results:")
print(f"  Overall Quality: {validation_result['overall_quality']:.2f}")
print(f"  Issues Found: {len(validation_result['issues'])}")

for issue in validation_result['issues']:
    print(f"\n  Issue Type: {issue['type']}")
    print(f"    Severity: {issue['severity']}")
    print(f"    Description: {issue['description']}")
    print(f"    Suggestion: {issue['suggestion']}")
```

### ç¤ºä¾‹2: å¸¦è‡ªåŠ¨ä¿®æ­£çš„å®Œæ•´pipeline

```python
# ä½¿ç”¨å®Œæ•´çš„å¤šé˜¶æ®µpipeline
pipeline = MultiStageDedupPipeline(
    enable_validation=True,
    enable_correction=True,
    validation_threshold=0.7  # è´¨é‡ä½äº0.7æ—¶è‡ªåŠ¨ä¿®æ­£
)

tails = [
    "Barack Obama",
    "Obama",
    "Barack H. Obama",
    "Donald Trump",
    "Trump",
    "Donald J. Trump"
]

contexts = [
    ["- Barack Obama was the 44th President"],
    ["- Obama served from 2009 to 2017"],
    ["- Barack H. Obama was born in Hawaii"],
    ["- Donald Trump was the 45th President"],
    ["- Trump served from 2017 to 2021"],
    ["- Donald J. Trump was born in New York"]
]

result = pipeline(
    head_entity="United States",
    relation="president",
    tail_descriptions=tails,
    contexts=contexts
)

print("\n=== Pipeline Results ===")
print(f"\nClusters: {len(result['clusters'])}")
print(f"Initial Groups: {len(result['initial_groups'])}")

if result['validation']:
    print(f"\nValidation Quality: {result['validation']['overall_quality']:.2f}")
    print(f"Issues: {len(result['validation']['issues'])}")

print(f"\nCorrections Applied: {result['corrections_applied']}")
print(f"Final Groups: {len(result['final_groups'])}")

for i, group in enumerate(result['final_groups'], 1):
    members = [tails[idx-1] for idx in group['members']]
    rep = tails[group['representative']-1]
    print(f"\nGroup {i}:")
    print(f"  Members: {members}")
    print(f"  Representative: {rep}")
```

### ç¤ºä¾‹3: æ‰¹é‡éªŒè¯å¹¶ç”ŸæˆæŠ¥å‘Š

```python
def validate_dedup_batch(dedup_results: List[Dict]) -> Dict:
    """
    æ‰¹é‡éªŒè¯å¤šä¸ªå»é‡ç»“æœï¼Œç”Ÿæˆè´¨é‡æŠ¥å‘Š
    """
    validation_module = DedupValidationModule()
    
    report = {
        "total": len(dedup_results),
        "high_quality": 0,  # quality >= 0.9
        "medium_quality": 0,  # 0.7 <= quality < 0.9
        "low_quality": 0,  # quality < 0.7
        "issues_summary": {
            "false_positive": 0,
            "false_negative": 0,
            "bad_representative": 0
        },
        "detailed_results": []
    }
    
    for item in dedup_results:
        validation = validation_module(
            head_entity=item['head_entity'],
            relation=item['relation'],
            original_tails=item['tails'],
            dedup_groups=item['groups'],
            contexts=item.get('contexts')
        )
        
        quality = validation['overall_quality']
        
        # Categorize quality
        if quality >= 0.9:
            report['high_quality'] += 1
        elif quality >= 0.7:
            report['medium_quality'] += 1
        else:
            report['low_quality'] += 1
        
        # Count issue types
        for issue in validation['issues']:
            issue_type = issue['type']
            if issue_type in report['issues_summary']:
                report['issues_summary'][issue_type] += 1
        
        report['detailed_results'].append({
            "head": item['head_entity'],
            "relation": item['relation'],
            "quality": quality,
            "issues": validation['issues']
        })
    
    return report

# ä½¿ç”¨ç¤ºä¾‹
batch_results = [
    {
        "head_entity": "United States",
        "relation": "president",
        "tails": ["Obama", "Barack Obama", "Trump"],
        "groups": [...],
        "contexts": [...]
    },
    # ... more results
]

report = validate_dedup_batch(batch_results)

print(f"Quality Report:")
print(f"  Total: {report['total']}")
print(f"  High Quality (â‰¥0.9): {report['high_quality']}")
print(f"  Medium Quality (0.7-0.9): {report['medium_quality']}")
print(f"  Low Quality (<0.7): {report['low_quality']}")
print(f"\nIssues Summary:")
for issue_type, count in report['issues_summary'].items():
    print(f"  {issue_type}: {count}")
```

---

## ğŸ¯ é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

### ä¿®æ”¹ `models/constructor/kt_gen.py`

```python
class KTBuilder:
    def __init__(self, ...):
        # ... ç°æœ‰ä»£ç  ...
        
        # åˆå§‹åŒ–validationæ¨¡å—
        if self._should_use_dspy_validation():
            self._init_dspy_validation()
    
    def _should_use_dspy_validation(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨DSPy validation"""
        config = self._get_semantic_dedup_config()
        if not config:
            return False
        
        dspy_config = getattr(config, 'dspy', None)
        if not dspy_config:
            return False
        
        return getattr(dspy_config, 'enable_validation', False)
    
    def _init_dspy_validation(self):
        """åˆå§‹åŒ–DSPy validationæ¨¡å—"""
        try:
            from models.constructor.dspy_validation import DedupValidationModule
            
            self.dspy_validation = DedupValidationModule(use_cot=True)
            logger.info("DSPy validation module initialized")
        except Exception as e:
            logger.warning(f"Failed to initialize DSPy validation: {e}")
            self.dspy_validation = None
    
    def _semantic_deduplicate_group(self, head_id: str, relation: str, edges: list) -> list:
        """
        å¸¦validationçš„è¯­ä¹‰å»é‡
        """
        # ... ç°æœ‰çš„å»é‡é€»è¾‘ ...
        # groups = self._llm_semantic_group(...)
        
        # æ·»åŠ validationæ­¥éª¤
        if hasattr(self, 'dspy_validation') and self.dspy_validation:
            try:
                validation_result = self.dspy_validation(
                    head_entity=head_text,
                    relation=relation,
                    original_tails=candidate_descriptions,
                    dedup_groups=groups,
                    contexts=[entry.get('context_summaries') for entry in entries]
                )
                
                quality = validation_result.get('overall_quality', 1.0)
                issues = validation_result.get('issues', [])
                
                # è®°å½•validationç»“æœ
                if save_intermediate:
                    edge_dedup_result['validation'] = {
                        'quality_score': quality,
                        'issues': issues,
                        'group_scores': validation_result.get('group_scores', [])
                    }
                
                # å¦‚æœè´¨é‡å¤ªä½ï¼Œå¯ä»¥é€‰æ‹©ï¼š
                # 1. è­¦å‘Šä½†ç»§ç»­
                # 2. å›é€€åˆ°embedding-based clustering
                # 3. è§¦å‘è‡ªåŠ¨ä¿®æ­£
                if quality < 0.5:
                    logger.warning(
                        f"Low quality dedup for {head_text} - {relation}: "
                        f"quality={quality:.2f}, issues={len(issues)}"
                    )
                
            except Exception as e:
                logger.warning(f"Validation failed: {e}")
        
        # ... ç»§ç»­ç°æœ‰é€»è¾‘ ...
        return edges
```

---

## ğŸ“Š Validation Metrics

### è¯„ä¼°validationæ¨¡å—çš„æŒ‡æ ‡

```python
def validation_metric(example, pred, trace=None) -> float:
    """
    è¯„ä¼°validationæ¨¡å—çš„æ€§èƒ½
    
    Args:
        example: åŒ…å«çœŸå®æ ‡ç­¾çš„æ ·æœ¬
            - true_quality: çœŸå®è´¨é‡åˆ†æ•°
            - true_issues: çœŸå®çš„é—®é¢˜åˆ—è¡¨
        pred: validationæ¨¡å—çš„è¾“å‡º
    
    Returns:
        ç»¼åˆè¯„åˆ† (0-100)
    """
    try:
        # æå–é¢„æµ‹ç»“æœ
        if hasattr(pred, 'validation_results'):
            pred_results = json_repair.loads(pred.validation_results)
        elif isinstance(pred, dict):
            pred_results = pred
        else:
            return 0.0
        
        pred_quality = pred_results.get('overall_quality', 0.5)
        pred_issues = pred_results.get('issues', [])
        
        # æå–çœŸå®æ ‡ç­¾
        true_quality = example.true_quality
        true_issues = example.true_issues
        
        # 1. Quality score accuracy
        quality_error = abs(pred_quality - true_quality)
        quality_score = max(0, 100 - quality_error * 100)
        
        # 2. Issue detection F1
        pred_issue_types = set([issue['type'] for issue in pred_issues])
        true_issue_types = set([issue['type'] for issue in true_issues])
        
        if len(pred_issue_types) == 0 and len(true_issue_types) == 0:
            issue_f1 = 100.0
        elif len(pred_issue_types) == 0 or len(true_issue_types) == 0:
            issue_f1 = 0.0
        else:
            tp = len(pred_issue_types & true_issue_types)
            fp = len(pred_issue_types - true_issue_types)
            fn = len(true_issue_types - pred_issue_types)
            
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            issue_f1 = 2 * precision * recall / (precision + recall) * 100 if (precision + recall) > 0 else 0
        
        # ç»¼åˆè¯„åˆ†
        final_score = 0.6 * quality_score + 0.4 * issue_f1
        
        return final_score
    
    except Exception as e:
        print(f"Error in validation_metric: {e}")
        return 0.0
```

---

## ğŸ”§ é…ç½®ç¤ºä¾‹

```yaml
# config/base_config.yaml
construction:
  semantic_dedup:
    enabled: true
    use_dspy: true
    
    dspy:
      # åŸºç¡€æ¨¡å—
      clustering_module_path: "models/dspy_optimized/clustering_module.json"
      dedup_module_path: "models/dspy_optimized/dedup_module_general.json"
      
      # Validationé…ç½® â­ NEW
      enable_validation: true
      validation_module_path: "models/dspy_optimized/validation_module.json"
      
      # Correctioné…ç½®
      enable_correction: false  # å¯é€‰ï¼šè‡ªåŠ¨ä¿®æ­£ä½è´¨é‡ç»“æœ
      correction_module_path: "models/dspy_optimized/correction_module.json"
      validation_threshold: 0.7  # ä½äºæ­¤é˜ˆå€¼è§¦å‘correction
      
      # Validationè¡Œä¸º
      validation_on_low_confidence: true  # åªå¯¹ä½ç½®ä¿¡åº¦ç»“æœéªŒè¯
      save_validation_results: true  # ä¿å­˜validationç»“æœåˆ°intermediate files
      
      fallback_to_original: true
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨Validation

**æ¨èåœºæ™¯**:
- âœ… å…³é”®relationï¼ˆå¦‚äººåã€åœ°åç­‰æ˜“æ··æ·†çš„ï¼‰
- âœ… é«˜ä»·å€¼æ•°æ®ï¼ˆé”™è¯¯ä»£ä»·é«˜ï¼‰
- âœ… ä¸ç¡®å®šçš„å»é‡ç»“æœï¼ˆLLM confidenceä½ï¼‰
- âœ… æ‰¹é‡å¤„ç†åçš„è´¨é‡æ£€æŸ¥

**ä¸æ¨èåœºæ™¯**:
- âŒ ç®€å•æ˜ç¡®çš„å»é‡ï¼ˆå¦‚å®Œå…¨ç›¸åŒçš„å­—ç¬¦ä¸²ï¼‰
- âŒ æˆæœ¬æ•æ„Ÿçš„åœºæ™¯ï¼ˆvalidationä¼šå¢åŠ APIè°ƒç”¨ï¼‰
- âŒ å®æ—¶æ€§è¦æ±‚æé«˜çš„åœºæ™¯

### 2. Validation vs Correction

| ç»´åº¦ | Validation | Correction |
|------|-----------|------------|
| **ç›®çš„** | æ£€æµ‹é—®é¢˜ | ä¿®å¤é—®é¢˜ |
| **æˆæœ¬** | ä½ï¼ˆ1æ¬¡APIè°ƒç”¨ï¼‰ | é«˜ï¼ˆ2-3æ¬¡APIè°ƒç”¨ï¼‰ |
| **ä½¿ç”¨åœºæ™¯** | è´¨é‡ç›‘æ§ã€æŠ¥å‘Š | è‡ªåŠ¨ä¿®å¤ã€äººå·¥å®¡æ ¸å‰ |
| **å»ºè®®** | é»˜è®¤å¯ç”¨ | è°¨æ…å¯ç”¨ |

### 3. ä¼˜åŒ–ç­–ç•¥

```python
# ç­–ç•¥1: é€‰æ‹©æ€§validationï¼ˆåªéªŒè¯ä½ç½®ä¿¡åº¦ç»“æœï¼‰
if confidence_score < 0.8:
    validation_result = validation_module(...)

# ç­–ç•¥2: æ‰¹é‡validationï¼ˆå‡å°‘APIè°ƒç”¨ï¼‰
validation_results = batch_validate([...])

# ç­–ç•¥3: å¼‚æ­¥validationï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
validation_future = async_validate(...)
# ... ç»§ç»­ä¸»æµç¨‹ ...
validation_result = validation_future.get()
```

---

## ğŸ“ è®­ç»ƒValidationæ¨¡å—

åˆ›å»ºvalidationè®­ç»ƒæ•°æ®ï¼š

```python
# è®­ç»ƒæ•°æ®æ ¼å¼
validation_examples = [
    dspy.Example(
        head_entity="United States",
        relation="president",
        original_tails=["Obama", "Barack Obama", "Trump"],
        dedup_groups=[
            {"members": [1, 2], "representative": 1, "rationale": "Same person"},
            {"members": [3], "representative": 3, "rationale": "Different person"}
        ],
        contexts=[...],
        # çœŸå®æ ‡ç­¾
        true_quality=0.95,  # è¿™ä¸ªå»é‡è´¨é‡å¾ˆé«˜
        true_issues=[],  # æ²¡æœ‰å‘ç°é—®é¢˜
    ).with_inputs("head_entity", "relation", "original_tails", "dedup_groups", "contexts"),
    
    dspy.Example(
        head_entity="Apple Inc.",
        relation="product",
        original_tails=["iPhone 13", "iPhone 14"],
        dedup_groups=[
            {"members": [1, 2], "representative": 1, "rationale": "Both iPhones"}
        ],
        contexts=[...],
        # çœŸå®æ ‡ç­¾
        true_quality=0.3,  # è¿™ä¸ªå»é‡æœ‰é—®é¢˜ï¼
        true_issues=[
            {
                "type": "false_positive",
                "severity": "high",
                "group_id": 0,
                "description": "iPhone 13 and iPhone 14 are different products",
                "suggestion": "Split into separate groups"
            }
        ]
    ).with_inputs("head_entity", "relation", "original_tails", "dedup_groups", "contexts"),
]
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### æ€§èƒ½æå‡
- âœ… **é”™è¯¯æ£€æµ‹ç‡**: 85-95%
- âœ… **False Positiveè¯†åˆ«**: 80-90%
- âœ… **False Negativeè¯†åˆ«**: 70-85%
- âœ… **è´¨é‡è¯„åˆ†å‡†ç¡®åº¦**: MAE < 0.1

### æˆæœ¬åˆ†æ
| é…ç½® | APIè°ƒç”¨æ¬¡æ•° | ç›¸å¯¹æˆæœ¬ |
|------|-----------|---------|
| æ— Validation | N | 1.0x |
| Validation | N + N/groups | 1.2x |
| Validation + Correction | N + N/groups + corrections*2 | 1.5-2.0x |

### ä»·å€¼
- ğŸ¯ **å‡å°‘äººå·¥å®¡æ ¸**: è‡ªåŠ¨è¯†åˆ«å¯ç–‘ç»“æœ
- ğŸ¯ **æå‡ç½®ä¿¡åº¦**: çŸ¥é“å“ªäº›ç»“æœå¯é 
- ğŸ¯ **æŒç»­æ”¹è¿›**: validationç»“æœå¯ç”¨äºè®­ç»ƒæ–°æ¨¡å‹

---

## âœ… æ€»ç»“

**DSPyå®Œå…¨æ”¯æŒvalidationï¼** 

å…³é”®ä¼˜åŠ¿ï¼š
1. âœ… å¤šé˜¶æ®µpipelineæ˜“äºæ„å»º
2. âœ… Validationé€»è¾‘å¯è‡ªåŠ¨ä¼˜åŒ–
3. âœ… æ”¯æŒè‡ªåŠ¨ä¿®æ­£ï¼ˆå¯é€‰ï¼‰
4. âœ… çµæ´»çš„é…ç½®å’Œä½¿ç”¨æ–¹å¼

å»ºè®®ï¼š
- **åŸºç¡€åœºæ™¯**: Dedup only
- **é‡è¦åœºæ™¯**: Dedup + Validation
- **å…³é”®åœºæ™¯**: Dedup + Validation + Human review
- **è‡ªåŠ¨åŒ–åœºæ™¯**: Full pipeline with Correction

ç«‹å³å¼€å§‹ä½¿ç”¨validationæå‡å»é‡è´¨é‡ï¼ğŸš€
